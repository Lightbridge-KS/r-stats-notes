[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stats & ML Notes",
    "section": "",
    "text": "Preface\n\n\n\n\n\n\nAbout\n\n\n\nThis is my notes on statistics and machine learning using R."
  },
  {
    "objectID": "stats/normality-test.html#explore-data",
    "href": "stats/normality-test.html#explore-data",
    "title": "Normality Test",
    "section": "Explore Data",
    "text": "Explore Data\n\nglimpse(ToothGrowth)\n#&gt; Rows: 60\n#&gt; Columns: 3\n#&gt; $ len  &lt;dbl&gt; 4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5,…\n#&gt; $ supp &lt;fct&gt; VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, V…\n#&gt; $ dose &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, …\n\n\nskimr::skim(ToothGrowth)\n\n\nData summary\n\n\nName\nToothGrowth\n\n\nNumber of rows\n60\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsupp\n0\n1\nFALSE\n2\nOJ: 30, VC: 30\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlen\n0\n1\n18.81\n7.65\n4.2\n13.07\n19.25\n25.27\n33.9\n▅▃▅▇▂\n\n\ndose\n0\n1\n1.17\n0.63\n0.5\n0.50\n1.00\n2.00\n2.0\n▇▇▁▁▇"
  },
  {
    "objectID": "stats/normality-test.html#normality-check",
    "href": "stats/normality-test.html#normality-check",
    "title": "Normality Test",
    "section": "Normality Check",
    "text": "Normality Check\n\n\n\n\n\n\nObjective\n\n\n\nWe want to test if the variable len (tooth length) is normally distributed."
  },
  {
    "objectID": "stats/normality-test.html#visual-method",
    "href": "stats/normality-test.html#visual-method",
    "title": "Normality Test",
    "section": "Visual Method",
    "text": "Visual Method\n\nHistogram\n\nToothGrowth %&gt;% \n  ggplot(aes(len)) +\n  geom_histogram()\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nDensity\n\nggdensity(ToothGrowth$len, fill = \"lightgray\")\n\n\n\n\n\n\nQQ Plot\n\nggqqplot(ToothGrowth$len)\n\n\n\n\n\nToothGrowth %&gt;% \n  ggplot(aes(sample = len)) +\n  geom_qq() +\n  geom_qq_line()"
  },
  {
    "objectID": "stats/normality-test.html#shapiro-wilks-normality-test",
    "href": "stats/normality-test.html#shapiro-wilks-normality-test",
    "title": "Normality Test",
    "section": "Shapiro-Wilk’s normality test",
    "text": "Shapiro-Wilk’s normality test\n\n\n\n\n\n\nHypothesis\n\n\n\n\\(H_0\\) = “sample distribution is normal”\n\n\n\nOne Variable\n\nshapiro.test(ToothGrowth$len)\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  ToothGrowth$len\n#&gt; W = 0.96743, p-value = 0.1091\n\nOr\n\nToothGrowth %&gt;% shapiro_test(len)\n#&gt; # A tibble: 1 × 3\n#&gt;   variable statistic     p\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 len          0.967 0.109\n\nP-value &gt; 0.05; implying that the distribution of the data are not significantly different from normal distribution; therefore, we can assume normality.\n\n\nGrouped Data\n\nToothGrowth %&gt;%\n  group_by(dose) %&gt;%\n  shapiro_test(len)\n#&gt; # A tibble: 3 × 4\n#&gt;    dose variable statistic     p\n#&gt;   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   0.5 len          0.941 0.247\n#&gt; 2   1   len          0.931 0.164\n#&gt; 3   2   len          0.978 0.902"
  },
  {
    "objectID": "stats/infer.html#explore-data",
    "href": "stats/infer.html#explore-data",
    "title": "Infer Package Intro",
    "section": "Explore Data",
    "text": "Explore Data\n\nglimpse(gss)\n#&gt; Rows: 500\n#&gt; Columns: 11\n#&gt; $ year    &lt;dbl&gt; 2014, 1994, 1998, 1996, 1994, 1996, 1990, 2016, 2000, 1998, 20…\n#&gt; $ age     &lt;dbl&gt; 36, 34, 24, 42, 31, 32, 48, 36, 30, 33, 21, 30, 38, 49, 25, 56…\n#&gt; $ sex     &lt;fct&gt; male, female, male, male, male, female, female, female, female…\n#&gt; $ college &lt;fct&gt; degree, no degree, degree, no degree, degree, no degree, no de…\n#&gt; $ partyid &lt;fct&gt; ind, rep, ind, ind, rep, rep, dem, ind, rep, dem, dem, ind, de…\n#&gt; $ hompop  &lt;dbl&gt; 3, 4, 1, 4, 2, 4, 2, 1, 5, 2, 4, 3, 4, 4, 2, 2, 3, 2, 1, 2, 5,…\n#&gt; $ hours   &lt;dbl&gt; 50, 31, 40, 40, 40, 53, 32, 20, 40, 40, 23, 52, 38, 72, 48, 40…\n#&gt; $ income  &lt;ord&gt; $25000 or more, $20000 - 24999, $25000 or more, $25000 or more…\n#&gt; $ class   &lt;fct&gt; middle class, working class, working class, working class, mid…\n#&gt; $ finrela &lt;fct&gt; below average, below average, below average, above average, ab…\n#&gt; $ weight  &lt;dbl&gt; 0.8960034, 1.0825000, 0.5501000, 1.0864000, 1.0825000, 1.08640…"
  },
  {
    "objectID": "stats/infer.html#specifying-response-specify",
    "href": "stats/infer.html#specifying-response-specify",
    "title": "Infer Package Intro",
    "section": "Specifying Response specify()",
    "text": "Specifying Response specify()\nSpecify response and explanatory variable as formula or arguments.\n\nContinuous Response\nage (num) ~ partyid (fct)\n\ngss_spec_age_partyid &lt;- gss %&gt;% \n  specify(age ~ partyid)\n#&gt; Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n\n# Object Type\nsloop::otype(gss_spec_age_partyid)\n#&gt; [1] \"S3\"\n# Class\nclass(gss_spec_age_partyid)\n#&gt; [1] \"infer\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n# Print\ngss_spec_age_partyid\n#&gt; Response: age (numeric)\n#&gt; Explanatory: partyid (factor)\n#&gt; # A tibble: 500 × 2\n#&gt;      age partyid\n#&gt;    &lt;dbl&gt; &lt;fct&gt;  \n#&gt;  1    36 ind    \n#&gt;  2    34 rep    \n#&gt;  3    24 ind    \n#&gt;  4    42 ind    \n#&gt;  5    31 rep    \n#&gt;  6    32 rep    \n#&gt;  7    48 dem    \n#&gt;  8    36 ind    \n#&gt;  9    30 rep    \n#&gt; 10    33 dem    \n#&gt; # … with 490 more rows\n\n\n\nCategorical Response\nspecifying for inference on proportions\nyou will need to use the success argument to specify which level of your response variable is a success.\n\ngss %&gt;%\n  specify(response = college, success = \"degree\")\n#&gt; Response: college (factor)\n#&gt; # A tibble: 500 × 1\n#&gt;    college  \n#&gt;    &lt;fct&gt;    \n#&gt;  1 degree   \n#&gt;  2 no degree\n#&gt;  3 degree   \n#&gt;  4 no degree\n#&gt;  5 degree   \n#&gt;  6 no degree\n#&gt;  7 no degree\n#&gt;  8 degree   \n#&gt;  9 degree   \n#&gt; 10 no degree\n#&gt; # … with 490 more rows"
  },
  {
    "objectID": "stats/infer.html#declare-the-null-hypothesis",
    "href": "stats/infer.html#declare-the-null-hypothesis",
    "title": "Infer Package Intro",
    "section": "Declare the NULL Hypothesis",
    "text": "Declare the NULL Hypothesis\ndeclare a null hypothesis using hypothesize().\nnull: “independence” or “point”.\n\nTest Independence\nIf the null hypothesis is that the mean number of hours worked per week in our population is 40, we would write:\n\ngss %&gt;%\n  specify(college ~ partyid, success = \"degree\") %&gt;%\n  hypothesize(null = \"independence\")\n#&gt; Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n#&gt; Response: college (factor)\n#&gt; Explanatory: partyid (factor)\n#&gt; Null Hypothesis: independence\n#&gt; # A tibble: 500 × 2\n#&gt;    college   partyid\n#&gt;    &lt;fct&gt;     &lt;fct&gt;  \n#&gt;  1 degree    ind    \n#&gt;  2 no degree rep    \n#&gt;  3 degree    ind    \n#&gt;  4 no degree ind    \n#&gt;  5 degree    rep    \n#&gt;  6 no degree rep    \n#&gt;  7 no degree dem    \n#&gt;  8 degree    ind    \n#&gt;  9 degree    rep    \n#&gt; 10 no degree dem    \n#&gt; # … with 490 more rows\n\n\n\nTest Point Estimate\n\ngss %&gt;%\n  specify(response = hours) %&gt;%\n  hypothesize(null = \"point\", mu = 40)\n#&gt; Response: hours (numeric)\n#&gt; Null Hypothesis: point\n#&gt; # A tibble: 500 × 1\n#&gt;    hours\n#&gt;    &lt;dbl&gt;\n#&gt;  1    50\n#&gt;  2    31\n#&gt;  3    40\n#&gt;  4    40\n#&gt;  5    40\n#&gt;  6    53\n#&gt;  7    32\n#&gt;  8    20\n#&gt;  9    40\n#&gt; 10    40\n#&gt; # … with 490 more rows"
  },
  {
    "objectID": "stats/infer.html#generate-null-distribution",
    "href": "stats/infer.html#generate-null-distribution",
    "title": "Infer Package Intro",
    "section": "generate() NULL distribution",
    "text": "generate() NULL distribution\n\nset.seed(1)\n\ngss %&gt;%\n  specify(response = hours) %&gt;%\n  hypothesize(null = \"point\", mu = 40) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\")\n#&gt; Response: hours (numeric)\n#&gt; Null Hypothesis: point\n#&gt; # A tibble: 500,000 × 2\n#&gt; # Groups:   replicate [1,000]\n#&gt;    replicate hours\n#&gt;        &lt;int&gt; &lt;dbl&gt;\n#&gt;  1         1 46.6 \n#&gt;  2         1 43.6 \n#&gt;  3         1 38.6 \n#&gt;  4         1 28.6 \n#&gt;  5         1 38.6 \n#&gt;  6         1 38.6 \n#&gt;  7         1  6.62\n#&gt;  8         1 78.6 \n#&gt;  9         1 38.6 \n#&gt; 10         1 38.6 \n#&gt; # … with 499,990 more rows"
  },
  {
    "objectID": "stats/infer.html#calculate-summary-stats",
    "href": "stats/infer.html#calculate-summary-stats",
    "title": "Infer Package Intro",
    "section": "Calculate Summary Stats",
    "text": "Calculate Summary Stats\nfind the point estimate\n\nobs_mean &lt;- gss %&gt;%\n  specify(response = hours) %&gt;%\n  calculate(stat = \"mean\")\n\nobs_mean\n#&gt; Response: hours (numeric)\n#&gt; # A tibble: 1 × 1\n#&gt;    stat\n#&gt;   &lt;dbl&gt;\n#&gt; 1  41.4\n\ngenerate a null distribution\n\nnull_dist &lt;- gss %&gt;%\n  specify(response = hours) %&gt;%\n  hypothesize(null = \"point\", mu = 40) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\") %&gt;%\n  calculate(stat = \"mean\")\n\nnull_dist\n#&gt; Response: hours (numeric)\n#&gt; Null Hypothesis: point\n#&gt; # A tibble: 1,000 × 2\n#&gt;    replicate  stat\n#&gt;        &lt;int&gt; &lt;dbl&gt;\n#&gt;  1         1  40.5\n#&gt;  2         2  40.1\n#&gt;  3         3  39.1\n#&gt;  4         4  40.3\n#&gt;  5         5  38.8\n#&gt;  6         6  39.6\n#&gt;  7         7  40.2\n#&gt;  8         8  40.4\n#&gt;  9         9  40.1\n#&gt; 10        10  40.6\n#&gt; # … with 990 more rows"
  },
  {
    "objectID": "stats/infer.html#visualize-null-dist",
    "href": "stats/infer.html#visualize-null-dist",
    "title": "Infer Package Intro",
    "section": "Visualize Null Dist",
    "text": "Visualize Null Dist\n\nnull_dist %&gt;%\n  visualize()\n\n\n\n\nWhere does our sample’s observed statistic lie on this distribution? We can use the obs_stat argument to specify this.\n\nnull_dist %&gt;%\n  visualize() +\n  shade_p_value(obs_stat = obs_mean, direction = \"two-sided\")"
  },
  {
    "objectID": "stats/infer.html#p-value",
    "href": "stats/infer.html#p-value",
    "title": "Infer Package Intro",
    "section": "P-value",
    "text": "P-value\nget a two-tailed p-value\n\np_value &lt;- null_dist %&gt;%\n  get_p_value(obs_stat = obs_mean, direction = \"two-sided\")\n\np_value\n#&gt; # A tibble: 1 × 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1   0.038"
  },
  {
    "objectID": "stats/infer.html#confidence-interval",
    "href": "stats/infer.html#confidence-interval",
    "title": "Infer Package Intro",
    "section": "Confidence Interval",
    "text": "Confidence Interval\n\n# generate a distribution like the null distribution, \n# though exclude the null hypothesis from the pipeline\nboot_dist &lt;- gss %&gt;%\n  specify(response = hours) %&gt;%\n  generate(reps = 1000, type = \"bootstrap\") %&gt;%\n  calculate(stat = \"mean\")\n\n# start with the bootstrap distribution\nci &lt;- boot_dist %&gt;%\n  # calculate the confidence interval around the point estimate\n  get_confidence_interval(point_estimate = obs_mean,\n                          # at the 95% confidence level\n                          level = .95,\n                          # using the standard error\n                          type = \"se\")\n\nci\n#&gt; # A tibble: 1 × 2\n#&gt;   lower_ci upper_ci\n#&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1     40.1     42.7\n\n\nboot_dist %&gt;%\n  visualize() +\n  shade_confidence_interval(endpoints = ci)"
  },
  {
    "objectID": "stats/wilcoxon.html#introduction",
    "href": "stats/wilcoxon.html#introduction",
    "title": "Wilcoxon Test",
    "section": "Introduction",
    "text": "Introduction\n\nThe Wilcoxon test is a non-parametric test for comparing 2 groups\nLess powerful than t-test, i.e., more likely to fail to reject the \\(H_0\\) that there is no difference.\n\n\nWhen to use\nData is not normally distributed and the sample size is small (n &lt; 30) (so that central limit theorem not applied)"
  },
  {
    "objectID": "stats/wilcoxon.html#wilcoxon-signed-rank-test-on-paired-samples",
    "href": "stats/wilcoxon.html#wilcoxon-signed-rank-test-on-paired-samples",
    "title": "Wilcoxon Test",
    "section": "Wilcoxon signed rank test on paired samples",
    "text": "Wilcoxon signed rank test on paired samples\n\nData\n\n# Wide format\ndata(\"mice2\", package = \"datarium\")\nhead(mice2, 3)\n#&gt;   id before after\n#&gt; 1  1  187.2 429.5\n#&gt; 2  2  194.2 404.4\n#&gt; 3  3  231.7 405.6\n\nTransform to long\n\nmice2.long &lt;- mice2 %&gt;%\n  gather(key = \"group\", value = \"weight\", before, after)\n\nhead(mice2.long, 3)\n#&gt;   id  group weight\n#&gt; 1  1 before  187.2\n#&gt; 2  2 before  194.2\n#&gt; 3  3 before  231.7\n\n\n\nSummary Stats\n\nmice2.long %&gt;%\n  group_by(group) %&gt;%\n  get_summary_stats(weight, type = \"median_iqr\")\n#&gt; # A tibble: 2 × 5\n#&gt;   group  variable     n median   iqr\n#&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 after  weight      10   405   28.3\n#&gt; 2 before weight      10   197.  19.2\n\n\nggpaired(mice2.long, x = \"group\", y = \"weight\", \n         order = c(\"before\", \"after\"),\n         ylab = \"Weight\", xlab = \"Groups\")\n\n\n\n\nThe test assumes that differences between paired samples should be distributed symmetrically around the median.\n\nmice2d &lt;- mice2 %&gt;% \n  mutate(differences = after - before)\n\ngghistogram(mice2d, x = \"differences\", y = \"..density..\", \n            fill = \"steelblue\",bins = 5, add_density = TRUE)\n\n\n\n\n\n\nComputation\n\nwilcox.test(weight ~ group, data = mice2.long, paired = TRUE)\n#&gt; \n#&gt;  Wilcoxon signed rank exact test\n#&gt; \n#&gt; data:  weight by group\n#&gt; V = 55, p-value = 0.001953\n#&gt; alternative hypothesis: true location shift is not equal to 0\n\nOr\n\nstat.test &lt;- mice2.long  %&gt;%\n  wilcox_test(weight ~ group, paired = TRUE) %&gt;%\n  add_significance()\n\nstat.test\n#&gt; # A tibble: 1 × 8\n#&gt;   .y.    group1 group2    n1    n2 statistic       p p.signif\n#&gt; * &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   \n#&gt; 1 weight after  before    10    10        55 0.00195 **\n\n\n\nEffect size\n\nmice2.long  %&gt;%\n  wilcox_effsize(weight ~ group, paired = TRUE)\n#&gt; # A tibble: 1 × 7\n#&gt;   .y.    group1 group2 effsize    n1    n2 magnitude\n#&gt; * &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n#&gt; 1 weight after  before   0.886    10    10 large\n\n\n\nViz ggplot2\n\nmice2.long %&gt;% \n  ggplot(aes(group, weight, color = group, fill = group)) +\n  geom_boxplot(alpha = 0.4) +\n  geom_jitter() +\n  ggpubr::stat_compare_means(method = \"wilcox.test\",\n                             paired = TRUE, \n                             label.x = 1.5, \n                             label.y = 450, \n                             show.legend = F)\n\n\n\n\n\n\nViz: {ggstatsplot}\n\nlibrary(ggstatsplot)\n\n\nset.seed(123) # Seed for bootstraped CI\n\nggwithinstats( # paired samples\n  data = mice2.long,\n  x = group,\n  y = weight,\n  type = \"nonparametric\", # for wilcoxon\n  centrality.plotting = FALSE # remove median\n)"
  },
  {
    "objectID": "stats/dta.html#survived-vs-fare-any-difference",
    "href": "stats/dta.html#survived-vs-fare-any-difference",
    "title": "Diagnosis Accuracy",
    "section": "Survived vs Fare: Any difference ?",
    "text": "Survived vs Fare: Any difference ?\nLet’s ask the following question: were those people who paid more for their ticket more likely to survive?\n\nggstatsplot::ggbetweenstats(\n  titanic_train,\n  x = Survived,\n  y = Fare\n)\n\n\n\n\nConfirm the difference in Fare between 2 groups.\n\nwilcox.test(titanic_train$Fare ~ titanic_train$Survived)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  titanic_train$Fare by titanic_train$Survived\nW = 57806, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "stats/dta.html#dta-manual-way",
    "href": "stats/dta.html#dta-manual-way",
    "title": "Diagnosis Accuracy",
    "section": "DTA (Manual Way)",
    "text": "DTA (Manual Way)\nNow let’s ask a slightly different question: can a passenger’s fare price be used to predict where or not they survived?\n\nPrep Data\n\ntitanic_sub &lt;- titanic_train |&gt; \n  select(Fare, Survived) |&gt; \n  mutate(Survived_orig = ifelse(Survived == 1L, \"Lived\", \"Died\")) |&gt; \n  mutate(Survived_pred = ifelse(Fare &gt; 14.45, \"Lived\", \"Died\")) |&gt; \n  mutate(across(starts_with(\"Survived_\"), \n                ~factor(.x, levels = c(\"Lived\", \"Died\"))))\n\nhead(titanic_sub)\n\n     Fare Survived Survived_orig Survived_pred\n1  7.2500        0          Died          Died\n2 71.2833        1         Lived         Lived\n3  7.9250        1         Lived          Died\n4 53.1000        1         Lived         Lived\n5  8.0500        0          Died          Died\n6  8.4583        0          Died          Died\n\n\n\n\nConfusion Matrix\n\ncm &lt;- table(pred = titanic_sub$Survived_pred, \n      orig = titanic_sub$Survived_orig)\n\ncm\n\n       orig\npred    Lived Died\n  Lived   231  220\n  Died    111  329\n\n\n\n\nDiagnostic Accuracy\n\n# True Positive\n(tp &lt;- cm[1, 1])\n\n[1] 231\n\n# False Positive\n(fp &lt;- cm[1, 2])\n\n[1] 220\n\n# False Negative\n(fn &lt;- cm[2, 1])\n\n[1] 111\n\n# True Negative\n(tn &lt;- cm[2, 2])\n\n[1] 329\n\n\n\n# Sense\ntp / (tp + fn)\n\n[1] 0.6754386\n\n# Spec\ntn / (tn + fp)\n\n[1] 0.5992714\n\n# PPV\ntp / (tp + fp)\n\n[1] 0.5121951\n\n# NPV\ntn / (tn + fn)\n\n[1] 0.7477273"
  },
  {
    "objectID": "stats/dta.html#roc-curve",
    "href": "stats/dta.html#roc-curve",
    "title": "Diagnosis Accuracy",
    "section": "ROC Curve",
    "text": "ROC Curve\n\nr1 &lt;- roc(Survived_orig ~ Fare, data = titanic_sub)\n\nSetting levels: control = Lived, case = Died\n\n\nSetting direction: controls &gt; cases\n\nr1\n\n\nCall:\nroc.formula(formula = Survived_orig ~ Fare, data = titanic_sub)\n\nData: Fare in 342 controls (Survived_orig Lived) &gt; 549 cases (Survived_orig Died).\nArea under the curve: 0.6921\n\n\n\n# AUC\n(auc &lt;- auc(r1))\n\nArea under the curve: 0.6921\n\n# Confidence Interval\n(ci &lt;- ci.auc(r1))\n\n95% CI: 0.6567-0.7276 (DeLong)\n\nci_l &lt;- round(ci[1], 2) # Lower\nci_u &lt;- round(ci[3], 2) # Upper\n\n\nhead(r1$thresholds)\n\n[1]      Inf 387.6646 262.6875 254.9479 237.5229 224.6521\n\n\n\nPlot (Base R)\n\nplot(r1, type = \"S\")\n\n\n\n\n\n\nPlot (ggplot2)\n\nlegend_text &lt;- paste0(\n    \"AUC = \", round(auc, 2), \" (95% CI = \", ci_l, \" - \", ci_u, \")\"\n)\n\n\nggroc(r1)+ \n  ggtitle(\"Receiver Operating Characteristic Curve\") +\n  geom_segment(\n    aes(x = 1, xend = 0, y = 0, yend = 1), color = \"grey\", \n    linetype = \"dashed\" ) +\n  scale_y_continuous(expand = c(0, 0)) + \n  scale_x_reverse(expand = c(0, 0)) + \n  annotate(\"text\", x = 0.3, y = 0.05, label = legend_text)\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale."
  },
  {
    "objectID": "stats/dta-yardstick.html#confusion-matric",
    "href": "stats/dta-yardstick.html#confusion-matric",
    "title": "DTA (Yardstick)",
    "section": "Confusion Matric",
    "text": "Confusion Matric\n\ncm &lt;- conf_mat(pathology, truth = pathology, estimate = scan) \ncm\n#&gt;           Truth\n#&gt; Prediction abnorm norm\n#&gt;     abnorm    231   32\n#&gt;     norm       27   54\n\n\nsummary(cm)\n#&gt; # A tibble: 13 × 3\n#&gt;    .metric              .estimator .estimate\n#&gt;    &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n#&gt;  1 accuracy             binary         0.828\n#&gt;  2 kap                  binary         0.534\n#&gt;  3 sens                 binary         0.895\n#&gt;  4 spec                 binary         0.628\n#&gt;  5 ppv                  binary         0.878\n#&gt;  6 npv                  binary         0.667\n#&gt;  7 mcc                  binary         0.534\n#&gt;  8 j_index              binary         0.523\n#&gt;  9 bal_accuracy         binary         0.762\n#&gt; 10 detection_prevalence binary         0.765\n#&gt; 11 precision            binary         0.878\n#&gt; 12 recall               binary         0.895\n#&gt; 13 f_meas               binary         0.887"
  },
  {
    "objectID": "stats/dta-yardstick.html#plot-bar-chart",
    "href": "stats/dta-yardstick.html#plot-bar-chart",
    "title": "DTA (Yardstick)",
    "section": "Plot Bar Chart",
    "text": "Plot Bar Chart\n\nautoplot(cm, type = \"mosaic\")\n\n\n\n\n\nautoplot(cm, type = \"heatmap\")\n\n\n\n\n\npathology_cell &lt;- pathology |&gt; \n  count(pathology, scan) |&gt; \n  mutate(prop = n/sum(n))\n\npathology_cell\n#&gt;   pathology   scan   n       prop\n#&gt; 1    abnorm abnorm 231 0.67151163\n#&gt; 2    abnorm   norm  27 0.07848837\n#&gt; 3      norm abnorm  32 0.09302326\n#&gt; 4      norm   norm  54 0.15697674\n\n\npathology_cell |&gt; \n  ggplot(aes(pathology, prop, fill = scan, color = scan)) +\n  geom_col(alpha = 0.5, position = \"fill\")"
  },
  {
    "objectID": "stats/dta-yardstick.html#metric-default",
    "href": "stats/dta-yardstick.html#metric-default",
    "title": "DTA (Yardstick)",
    "section": "Metric: Default",
    "text": "Metric: Default\n\npathology |&gt; metrics(truth = pathology, estimate = scan)\n#&gt; # A tibble: 2 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.828\n#&gt; 2 kap      binary         0.534"
  },
  {
    "objectID": "stats/dta-yardstick.html#metric-set",
    "href": "stats/dta-yardstick.html#metric-set",
    "title": "DTA (Yardstick)",
    "section": "Metric Set",
    "text": "Metric Set\n\nclass_metrics_1 &lt;- metric_set(accuracy, sens, spec, ppv, npv)\n\n\npathology |&gt; class_metrics_1(truth = pathology, estimate = scan)\n#&gt; # A tibble: 5 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.828\n#&gt; 2 sens     binary         0.895\n#&gt; 3 spec     binary         0.628\n#&gt; 4 ppv      binary         0.878\n#&gt; 5 npv      binary         0.667"
  },
  {
    "objectID": "stats/dta-yardstick.html#custom-class-metric",
    "href": "stats/dta-yardstick.html#custom-class-metric",
    "title": "DTA (Yardstick)",
    "section": "Custom Class Metric",
    "text": "Custom Class Metric\nMiss Rate Example"
  },
  {
    "objectID": "stats/dta-yardstick.html#custom-lr-lr-",
    "href": "stats/dta-yardstick.html#custom-lr-lr-",
    "title": "DTA (Yardstick)",
    "section": "Custom LR+ & LR-",
    "text": "Custom LR+ & LR-\nFrom: How to implemen custom metric set\n\nFormular\nThe positive likelihood ratio is calculated as:\n\\[\n{\\displaystyle {\\text{LR}}+={\\frac {\\text{sensitivity}}{1-{\\text{specificity}}}}}\n\\]\n\\[\n{\\displaystyle {\\text{LR}}+={\\frac {\\text{TP / (TP + FN)}}{\\text{FP / (FP + TN)}}}}\n\\]\nThe negative likelihood ratio is calculated as:\n\\[\n{\\displaystyle {\\text{LR}}-={\\frac {1-{\\text{sensitivity}}}{\\text{specificity}}}}\n\\]\n\\[\n{\\displaystyle {\\text{LR}}-={\\frac {\\text{FN / (TP + FN)}}{\\text{TN / (FP + TN)}}}}\n\\]\n\n\nExample\n\npathology_xtab &lt;- table(pathology$scan, pathology$pathology) \npathology_xtab\n#&gt;         \n#&gt;          abnorm norm\n#&gt;   abnorm    231   32\n#&gt;   norm       27   54\n\n\n\nHelpers\n\n# Logic for `event_level`\nevent_col &lt;- function(xtab, event_level) {\n  if (identical(event_level, \"first\")) {\n    colnames(xtab)[[1]]\n  } else {\n    colnames(xtab)[[2]]\n  }\n}\n\n\nfinalize_estimator_internal.lr_pos &lt;- function(metric_dispatcher, x, estimator, call) {\n  \n  validate_estimator(estimator, estimator_override = \"binary\")\n  if (!is.null(estimator)) {\n    return(estimator)\n  }\n  \n  lvls &lt;- levels(x)\n  if (length(lvls) &gt; 2) {\n    stop(\"A multiclass `truth` input was provided, but only `binary` is supported.\")\n  } \n  \"binary\"\n}\n\n\n\nImplement\n\nLR Pos\n\nlr_pos_impl &lt;- function(truth, estimate, estimator, event_level) {\n  xtab &lt;- table(estimate, truth)\n  # Rather than implement the actual method here, we rely on\n  # an *_estimator_impl() function that can handle binary\n  # and multiclass cases\n  lr_pos_estimator_impl(xtab, estimator, event_level)\n}\n\n\n# This function switches between binary and multiclass implementations\nlr_pos_estimator_impl &lt;- function(data, estimator, event_level) {\n  if(estimator == \"binary\") {\n    lr_pos_binary(data, event_level)\n  } else {\n    # Encapsulates the macro, macro weighted, and micro cases\n    # TODO\n  }\n}\n\n\n\nLR Neg\n\nlr_neg_impl &lt;- function(truth, estimate, estimator, event_level) {\n  xtab &lt;- table(estimate, truth)\n  # Rather than implement the actual method here, we rely on\n  # an *_estimator_impl() function that can handle binary\n  # and multiclass cases\n  lr_neg_estimator_impl(xtab, estimator, event_level)\n}\n\n\n# This function switches between binary and multiclass implementations\nlr_neg_estimator_impl &lt;- function(data, estimator, event_level) {\n  if(estimator == \"binary\") {\n    lr_neg_binary(data, event_level)\n  } else {\n    # Encapsulates the macro, macro weighted, and micro cases\n    # TODO\n  }\n}\n\n\n\n\nBinary Implementation\n\nLR Pos\n\nlr_pos_binary &lt;- function(data, event_level) {\n  col &lt;- event_col(data, event_level)\n  col2 &lt;- setdiff(colnames(data), col)\n  \n  tp &lt;- data[col, col]\n  tn &lt;- data[col2, col2]\n  fp &lt;- data[col, col2]\n  fn &lt;- data[col2, col]\n  # list(tp = tp, tn = tn, fp = fp, fn = fn)\n  (tp / (tp + fn)) / (fp / (fp + tn))\n  \n}\n\nlr_pos_binary(pathology_xtab, event_level = \"first\")\n#&gt; [1] 2.40625\n\n\n\nLR Neg\n\nlr_neg_binary &lt;- function(data, event_level) {\n  col &lt;- event_col(data, event_level)\n  col2 &lt;- setdiff(colnames(data), col)\n  \n  tp &lt;- data[col, col]\n  tn &lt;- data[col2, col2]\n  fp &lt;- data[col, col2]\n  fn &lt;- data[col2, col]\n  # list(tp = tp, tn = tn, fp = fp, fn = fn)\n  (fn / (tp + fn)) / (tn / (fp + tn))\n  \n}\n\nlr_neg_binary(pathology_xtab, event_level = \"first\")\n#&gt; [1] 0.1666667\n\n\n# Checking\npathology_xtab\n#&gt;         \n#&gt;          abnorm norm\n#&gt;   abnorm    231   32\n#&gt;   norm       27   54\ncolnames(pathology_xtab)\n#&gt; [1] \"abnorm\" \"norm\"\n\n# TP\npathology_xtab[\"abnorm\", \"abnorm\"]\n#&gt; [1] 231\n# TN\npathology_xtab[\"norm\", \"norm\"]\n#&gt; [1] 54\n# FP\npathology_xtab[\"abnorm\", \"norm\"]\n#&gt; [1] 32\n# FN\npathology_xtab[\"norm\", \"abnorm\"]\n#&gt; [1] 27\n\n\n\n\nMulticlass Implementation\n[TODO]\n\n\nVec implement\n\nLR Pos\n\nlr_pos_vec &lt;- function(truth,\n                       estimate,\n                       estimator = NULL,\n                       na_rm = TRUE,\n                       case_weights = NULL,\n                       event_level = \"first\",\n                       ...) {\n  # calls finalize_estimator_internal() internally\n  estimator &lt;- finalize_estimator(truth, estimator, metric_class = \"lr_pos\")\n\n  check_class_metric(truth, estimate, case_weights, estimator)\n\n  if (na_rm) {\n    result &lt;- yardstick_remove_missing(truth, estimate, case_weights)\n\n    truth &lt;- result$truth\n    estimate &lt;- result$estimate\n    case_weights &lt;- result$case_weights\n  } else if (yardstick_any_missing(truth, estimate, case_weights)) {\n    return(NA_real_)\n  }\n\n  lr_pos_impl(truth, estimate, estimator, event_level)\n}\n\nlr_pos_vec(pathology$pathology, pathology$scan)\n#&gt; [1] 2.40625\n\n\n\nLR Neg\n\nlr_neg_vec &lt;- function(truth,\n                       estimate,\n                       estimator = NULL,\n                       na_rm = TRUE,\n                       case_weights = NULL,\n                       event_level = \"first\",\n                       ...) {\n  # calls finalize_estimator_internal() internally\n  estimator &lt;- finalize_estimator(truth, estimator, metric_class = \"lr_neg\")\n\n  check_class_metric(truth, estimate, case_weights, estimator)\n\n  if (na_rm) {\n    result &lt;- yardstick_remove_missing(truth, estimate, case_weights)\n\n    truth &lt;- result$truth\n    estimate &lt;- result$estimate\n    case_weights &lt;- result$case_weights\n  } else if (yardstick_any_missing(truth, estimate, case_weights)) {\n    return(NA_real_)\n  }\n\n  lr_neg_impl(truth, estimate, estimator, event_level)\n}\n\nlr_neg_vec(pathology$pathology, pathology$scan)\n#&gt; [1] 0.1666667\n\n\n\n\nDF implement\n\n# LR Pos\nlr_pos &lt;- function(data, ...) {\n  UseMethod(\"lr_pos\")\n}\n\nlr_pos &lt;- new_class_metric(lr_pos, direction = \"maximize\")\n\n# LR Neg\nlr_neg &lt;- function(data, ...) {\n  UseMethod(\"lr_neg\")\n}\n\nlr_neg &lt;- new_class_metric(lr_neg, direction = \"minimize\")\n\n\nlr_pos.data.frame &lt;- function(data,\n                              truth,\n                              estimate,\n                              estimator = NULL,\n                              na_rm = TRUE,\n                              case_weights = NULL,\n                              event_level = \"first\",\n                              ...) {\n  class_metric_summarizer(\n    name = \"lr_pos\",\n    fn = lr_pos_vec,\n    data = data,\n    truth = !!rlang::enquo(truth),\n    estimate = !!rlang::enquo(estimate),\n    estimator = estimator,\n    na_rm = na_rm,\n    case_weights = !!rlang::enquo(case_weights),\n    event_level = event_level\n  )\n}\n\n\nlr_neg.data.frame &lt;- function(data,\n                              truth,\n                              estimate,\n                              estimator = NULL,\n                              na_rm = TRUE,\n                              case_weights = NULL,\n                              event_level = \"first\",\n                              ...) {\n  class_metric_summarizer(\n    name = \"lr_neg\",\n    fn = lr_neg_vec,\n    data = data,\n    truth = !!rlang::enquo(truth),\n    estimate = !!rlang::enquo(estimate),\n    estimator = estimator,\n    na_rm = na_rm,\n    case_weights = !!rlang::enquo(case_weights),\n    event_level = event_level\n  )\n}\n\n\n\nUsing lr_pos()\n\nlr_pos(pathology, truth = pathology, estimate = scan)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 lr_pos  binary          2.41\n\n\nlr_pos_vec(truth = pathology$pathology, estimate = pathology$scan)\n#&gt; [1] 2.40625\n\n\n\nUsing lr_neg()\n\nlr_neg(pathology, truth = pathology, estimate = scan)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 lr_neg  binary         0.167\n\n\nlr_neg_vec(truth = pathology$pathology, estimate = pathology$scan)\n#&gt; [1] 0.1666667\n\n\n\nUsing with metric_set()\n\nclass_metrics_2 &lt;- metric_set(accuracy, sens, spec, lr_pos, lr_neg)\nclass_metrics_2\n#&gt; # A tibble: 5 × 3\n#&gt;   metric   class        direction\n#&gt;   &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;    \n#&gt; 1 accuracy class_metric maximize \n#&gt; 2 sens     class_metric maximize \n#&gt; 3 spec     class_metric maximize \n#&gt; 4 lr_pos   class_metric maximize \n#&gt; 5 lr_neg   class_metric minimize\n\n\nconf_mat(pathology, truth = pathology, estimate = scan)\n#&gt;           Truth\n#&gt; Prediction abnorm norm\n#&gt;     abnorm    231   32\n#&gt;     norm       27   54\n\n\nclass_metrics_2(pathology, truth = pathology, estimate = scan)\n#&gt; # A tibble: 5 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.828\n#&gt; 2 sens     binary         0.895\n#&gt; 3 spec     binary         0.628\n#&gt; 4 lr_pos   binary         2.41 \n#&gt; 5 lr_neg   binary         0.167\n\nCheck LR+\n\n0.8953488   / (1 - 0.6279070) # LR+ = Sens / (1-Spec)\n#&gt; [1] 2.40625\n\nCheck LR-\n\n(1 - 0.8953488) / 0.6279070  # LR- = (1-Sens) / Spec\n#&gt; [1] 0.1666667"
  },
  {
    "objectID": "stats/perf-mat.html#pre-processing",
    "href": "stats/perf-mat.html#pre-processing",
    "title": "Multi-class Performance Matrix",
    "section": "Pre-processing",
    "text": "Pre-processing\n\nset.seed(1)\niris_split &lt;- initial_split(iris, prop = 0.7, strata = Species)\niris_tr &lt;- training(iris_split)\niris_tst &lt;- testing(iris_split)\n\nRecipes\n\niris_rec &lt;- recipe(Species ~ ., data = iris) \n\nModel Spec\n\nmultinom_sim &lt;- multinom_reg(engine = \"nnet\")\n\nWorkflow\n\niris_wf &lt;- workflow(iris_rec, multinom_sim)"
  },
  {
    "objectID": "stats/perf-mat.html#fit-predict",
    "href": "stats/perf-mat.html#fit-predict",
    "title": "Multi-class Performance Matrix",
    "section": "Fit & Predict",
    "text": "Fit & Predict\nFit Model\n\niris_fit &lt;- fit(iris_wf, data = iris_tr)\niris_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nCall:\nnnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n\nCoefficients:\n           (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width\nversicolor    53.35203     3.845927   -31.93694     10.02870   -3.275975\nvirginica    -57.85131   -23.541980   -41.71563     61.61759   31.272313\n\nResidual Deviance: 0.1554973 \nAIC: 20.1555 \n\n\nPredict\n\niris_res &lt;- broom::augment(iris_fit, new_data = iris_tst)\nhead(iris_res)\n\n# A tibble: 6 × 9\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species .pred_class\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;      \n1          4.9         3            1.4         0.2 setosa  setosa     \n2          5           3.6          1.4         0.2 setosa  setosa     \n3          5.4         3.7          1.5         0.2 setosa  setosa     \n4          4.8         3            1.4         0.1 setosa  setosa     \n5          5.7         4.4          1.5         0.4 setosa  setosa     \n6          5.4         3.9          1.3         0.4 setosa  setosa     \n# ℹ 3 more variables: .pred_setosa &lt;dbl&gt;, .pred_versicolor &lt;dbl&gt;,\n#   .pred_virginica &lt;dbl&gt;"
  },
  {
    "objectID": "stats/perf-mat.html#multi-class-performace-matrix",
    "href": "stats/perf-mat.html#multi-class-performace-matrix",
    "title": "Multi-class Performance Matrix",
    "section": "Multi-class Performace Matrix",
    "text": "Multi-class Performace Matrix\n\nConfusion Matrix\n\nconf_mat(iris_res, truth = Species, estimate = .pred_class)\n\n            Truth\nPrediction   setosa versicolor virginica\n  setosa         14          0         0\n  versicolor      1         13         0\n  virginica       0          2        15\n\n\nCount number of observed class\n\nclass_totals &lt;- iris_res |&gt; \n  count(Species, name = \"totals\") %&gt;% \n  mutate(class_wts = totals / sum(totals))\n\nclass_totals\n\n# A tibble: 3 × 3\n  Species    totals class_wts\n  &lt;fct&gt;       &lt;int&gt;     &lt;dbl&gt;\n1 setosa         15     0.333\n2 versicolor     15     0.333\n3 virginica      15     0.333\n\n\n\ncell_counts &lt;- \n  iris_res %&gt;% \n  group_by(Species, .pred_class) %&gt;% \n  count() %&gt;% \n  ungroup()\n\ncell_counts\n\n# A tibble: 5 × 3\n  Species    .pred_class     n\n  &lt;fct&gt;      &lt;fct&gt;       &lt;int&gt;\n1 setosa     setosa         14\n2 setosa     versicolor      1\n3 versicolor versicolor     13\n4 versicolor virginica       2\n5 virginica  virginica      15\n\n\n\n# Compute the four sensitivities using 1-vs-all\none_versus_all &lt;- \n  cell_counts %&gt;% \n  filter(Species == .pred_class) %&gt;% \n  full_join(class_totals, by = \"Species\") %&gt;% \n  mutate(sens = n / totals)\n\none_versus_all\n\n# A tibble: 3 × 6\n  Species    .pred_class     n totals class_wts  sens\n  &lt;fct&gt;      &lt;fct&gt;       &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 setosa     setosa         14     15     0.333 0.933\n2 versicolor versicolor     13     15     0.333 0.867\n3 virginica  virginica      15     15     0.333 1    \n\n\n\n# Three different estimates:\none_versus_all %&gt;% \n  summarize(\n    macro = mean(sens), \n    macro_wts = weighted.mean(sens, class_wts),\n    micro = sum(n) / sum(totals)\n  )\n\n# A tibble: 1 × 3\n  macro macro_wts micro\n  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 0.933     0.933 0.933\n\n\n\nMacro-averaging: computes a set of one-versus-all metrics using the standard two-class statistics. These are averaged.\nMacro-weighted averaging: does the same but the average is weighted by the number of samples in each class.\nMicro-averaging: computes the contribution for each class, aggregates them, then computes a single metric from the aggregates.\n\n\n\n\nMulticlass Doodles"
  },
  {
    "objectID": "ml/tidymod-overview.html#explore-data",
    "href": "ml/tidymod-overview.html#explore-data",
    "title": "Tidymodels Overview",
    "section": "Explore Data",
    "text": "Explore Data\nOutcome: species\n\nglimpse(pen)\n\nRows: 344\nColumns: 5\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n\n\n\npen |&gt;\n  filter(!is.na(sex)) |&gt;\n  ggplot(aes(x     = flipper_length_mm,\n             y     = bill_depth_mm,\n             color = species,\n             size  = body_mass_g)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~sex)\n\n\n\n\nFigure 7.1: ?(caption)\n\n\n\n\n\npen |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nComplete record rate:\n\nvapply(pen, function(x) mean(!is.na(x)), numeric(1))\n\n          species     bill_depth_mm flipper_length_mm       body_mass_g \n        1.0000000         0.9941860         0.9941860         0.9941860 \n              sex \n        0.9680233"
  },
  {
    "objectID": "ml/tidymod-overview.html#data-budget",
    "href": "ml/tidymod-overview.html#data-budget",
    "title": "Tidymodels Overview",
    "section": "Data Budget",
    "text": "Data Budget\n\nSplit Data\n\nset.seed(123)\npen_split &lt;- initial_split(pen, prop = 0.8, strata = species)\npen_split\n\n&lt;Training/Testing/Total&gt;\n&lt;274/70/344&gt;\n\npen_train &lt;- training(pen_split)\npen_test &lt;- testing(pen_split)\n\n\n\nResample\n10-folded CV, repeated 2 times from the training data\n\nset.seed(123)\npen_folds &lt;- vfold_cv(pen_train, v = 10)\n\nhead(pen_folds)\n\n# A tibble: 6 × 2\n  splits           id    \n  &lt;list&gt;           &lt;chr&gt; \n1 &lt;split [246/28]&gt; Fold01\n2 &lt;split [246/28]&gt; Fold02\n3 &lt;split [246/28]&gt; Fold03\n4 &lt;split [246/28]&gt; Fold04\n5 &lt;split [247/27]&gt; Fold05\n6 &lt;split [247/27]&gt; Fold06"
  },
  {
    "objectID": "ml/tidymod-overview.html#recipes",
    "href": "ml/tidymod-overview.html#recipes",
    "title": "Tidymodels Overview",
    "section": "Recipes",
    "text": "Recipes\n\npen_rec_base &lt;- recipe(species ~ ., data = pen_train) \npen_rec_base\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 4"
  },
  {
    "objectID": "ml/tidymod-overview.html#model-spec",
    "href": "ml/tidymod-overview.html#model-spec",
    "title": "Tidymodels Overview",
    "section": "Model Spec",
    "text": "Model Spec\n\nmspec_cls &lt;- list(\n  multi_nnet = multinom_reg(engine = \"nnet\"),\n  multi_glmnet_lasso = multinom_reg(engine = \"glmnet\", \n                                    penalty = 0.1, mixture = 1)\n)\n\nmap(mspec_cls, translate)\n\n$multi_nnet\nMultinomial Regression Model Specification (classification)\n\nComputational engine: nnet \n\nModel fit template:\nnnet::multinom(formula = missing_arg(), data = missing_arg(), \n    trace = FALSE)\n\n$multi_glmnet_lasso\nMultinomial Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.1\n  mixture = 1\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    alpha = 1, family = \"multinomial\")"
  },
  {
    "objectID": "ml/tidymod-overview.html#workflow",
    "href": "ml/tidymod-overview.html#workflow",
    "title": "Tidymodels Overview",
    "section": "Workflow",
    "text": "Workflow\n\nSingle\n\nworkflow(preprocessor = pen_rec_base, spec = mspec_cls$multi_nnet)\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nMultinomial Regression Model Specification (classification)\n\nComputational engine: nnet \n\n\n\n\nCombinations\n\npen_wfset &lt;- workflow_set(\n  preproc = list(base = pen_rec_base),\n  models = mspec_cls\n)\n\npen_wfset\n\n# A workflow set/tibble: 2 × 4\n  wflow_id                info             option    result    \n  &lt;chr&gt;                   &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 base_multi_nnet         &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 base_multi_glmnet_lasso &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n\npen_wf_base &lt;- extract_workflow(pen_wfset, id = \"base_multi_nnet\")\npen_wf_base\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nMultinomial Regression Model Specification (classification)\n\nComputational engine: nnet"
  },
  {
    "objectID": "ml/tidymod-overview.html#other-spec",
    "href": "ml/tidymod-overview.html#other-spec",
    "title": "Tidymodels Overview",
    "section": "Other Spec",
    "text": "Other Spec\n\nPerformance Matric Spec\nA function factory\n\nmet_set_class &lt;- metric_set(\n  accuracy, sensitivity, specificity,\n  mcc # Matthews correlation coefficient\n)\n\nmet_set_mix &lt;- metric_set(roc_auc, accuracy, sensitivity, specificity)\n\n\n\nResamples Control\n\nkeep_pred &lt;- control_resamples(save_pred = TRUE, save_workflow = TRUE)"
  },
  {
    "objectID": "ml/tidymod-overview.html#fit",
    "href": "ml/tidymod-overview.html#fit",
    "title": "Tidymodels Overview",
    "section": "Fit",
    "text": "Fit\n\nUsing: Test Data\n\npen_fit_base &lt;- fit(pen_wf_base, data = pen_test)\npen_fit_base\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nCall:\nnnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n\nCoefficients:\n          (Intercept) bill_depth_mm flipper_length_mm  body_mass_g   sexmale\nChinstrap -21.7033319     -0.555911         0.1906063 -0.001596491 0.7168018\nGentoo     -0.4884471     -6.002835         0.2447407  0.011754103 3.8349607\n\nResidual Deviance: 46.77568 \nAIC: 66.77568 \n\n\n\n\nUsing: Resamples\n\n# Unix and macOS only\nlibrary(doMC)\n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nregisterDoMC(cores = 4)\n\n\npen_fit_fold_base &lt;- fit_resamples(pen_wf_base, \n                                   resamples = pen_folds,\n                                   metrics = met_set_mix,\n                                   control = keep_pred)\nhead(pen_fit_fold_base)\n\n# A tibble: 6 × 5\n  splits           id     .metrics         .notes           .predictions     \n  &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;           &lt;list&gt;           \n1 &lt;split [246/28]&gt; Fold01 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [28 × 7]&gt;\n2 &lt;split [246/28]&gt; Fold02 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [28 × 7]&gt;\n3 &lt;split [246/28]&gt; Fold03 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [28 × 7]&gt;\n4 &lt;split [246/28]&gt; Fold04 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [28 × 7]&gt;\n5 &lt;split [247/27]&gt; Fold05 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [27 × 7]&gt;\n6 &lt;split [247/27]&gt; Fold06 &lt;tibble [4 × 4]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble [27 × 7]&gt;"
  },
  {
    "objectID": "ml/tidymod-overview.html#evaluate-predict",
    "href": "ml/tidymod-overview.html#evaluate-predict",
    "title": "Tidymodels Overview",
    "section": "Evaluate & Predict",
    "text": "Evaluate & Predict\n\nUsing: Test set\n\nPredict\n\npen_res_base &lt;- broom::augment(pen_fit_base, new_data = pen_test)\nglimpse(pen_res_base)\n\nRows: 70\nColumns: 9\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, 17.1, 20.7, 18.4, 17.9, 17.8, 21.1…\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, 186, 197, 184, 187, 188, 196, 179, 19…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, 3300, 4500, 3325, 3200, 3300, 4150…\n$ sex               &lt;fct&gt; male, female, female, NA, male, female, female, fema…\n$ .pred_class       &lt;fct&gt; Adelie, Adelie, Chinstrap, NA, Adelie, Adelie, Adeli…\n$ .pred_Adelie      &lt;dbl&gt; 0.9463005, 0.8797500, 0.4329285, NA, 0.8936564, 0.89…\n$ .pred_Chinstrap   &lt;dbl&gt; 0.05369946, 0.12024966, 0.56707149, NA, 0.10634361, …\n$ .pred_Gentoo      &lt;dbl&gt; 1.147426e-09, 3.454101e-07, 6.534172e-11, NA, 2.2390…\n\n\n\n\nMetric\n\nmet_set_class(pen_res_base, \n              truth = species, \n              estimate = .pred_class,\n              estimator = \"macro\" # Macro AVG\n              )\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy    multiclass     0.809\n2 sensitivity macro          0.727\n3 specificity macro          0.896\n4 mcc         multiclass     0.704\n\n\n\n\nROC\n\nroc_curve(pen_res_base, truth = species, \n          .pred_Adelie, .pred_Chinstrap, .pred_Gentoo) |&gt; \n  autoplot()\n\n\n\n\nGentoo curve is on the top-left see Figure 7.1 for reason.\n\nroc_auc(pen_res_base, truth = species, \n        .pred_Adelie, .pred_Chinstrap, .pred_Gentoo)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.933\n\n\n\n\n\nUsing Resamples\n\nMetric\n\ncollect_metrics(pen_fit_fold_base)\n\n# A tibble: 4 × 6\n  .metric     .estimator  mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    multiclass 0.823    10  0.0227 Preprocessor1_Model1\n2 roc_auc     hand_till  0.918    10  0.0166 Preprocessor1_Model1\n3 sensitivity macro      0.753    10  0.0231 Preprocessor1_Model1\n4 specificity macro      0.904    10  0.0110 Preprocessor1_Model1\n\n\nThese are the resampling estimates averaged over the individual replicates. To get the metrics for each resample, use the option summarize = FALSE.\n\n\nPredictions\nAssessment set predictions:\n\npen_assess_base &lt;- collect_predictions(pen_fit_fold_base, summarize = FALSE)\nhead(pen_assess_base)\n\n# A tibble: 6 × 8\n  id     .pred_Adelie .pred_Chinstrap .pred_Gentoo  .row .pred_class species\n  &lt;chr&gt;         &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt;  \n1 Fold01        0.792          0.208      4.02e-25    10 Adelie      Adelie \n2 Fold01        0.691          0.309      3.25e-18    17 Adelie      Adelie \n3 Fold01        0.982          0.0177     7.24e-12    19 Adelie      Adelie \n4 Fold01        0.979          0.0209     2.11e-22    22 Adelie      Adelie \n5 Fold01        0.846          0.154      4.46e-12    46 Adelie      Adelie \n6 Fold01        0.880          0.120      5.82e-14    51 Adelie      Adelie \n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\n.row column is an integer that matches the row of the original training set so that these results can be properly arranged and joined with the original data.\nAveraged Predictions:\n\ncollect_predictions(pen_fit_fold_base, summarize = T) |&gt; head()\n\n# A tibble: 6 × 7\n   .row species .config    .pred_Adelie .pred_Chinstrap .pred_Gentoo .pred_class\n  &lt;int&gt; &lt;fct&gt;   &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt; &lt;fct&gt;      \n1     1 Adelie  Preproces…      NaN            NaN        NaN        Adelie     \n2     2 Adelie  Preproces…        0.514          0.486      1.41e-17 Adelie     \n3     3 Adelie  Preproces…        0.874          0.126      8.77e-21 Adelie     \n4     4 Adelie  Preproces…        0.949          0.0509     1.53e-14 Adelie     \n5     5 Adelie  Preproces…        0.791          0.209      4.07e-13 Adelie     \n6     6 Adelie  Preproces…      NaN            NaN        NaN        Adelie     \n\n\n\n\nROC\n\npen_assess_base |&gt; \n  group_by(id) |&gt; \n  roc_curve(truth = species, .pred_Adelie, .pred_Chinstrap, .pred_Gentoo) |&gt; \n  autoplot()"
  },
  {
    "objectID": "ml/ml-ops.html#eda",
    "href": "ml/ml-ops.html#eda",
    "title": "ML Ops with Penguin",
    "section": "EDA",
    "text": "EDA\n\npenguins |&gt;\n  filter(!is.na(sex)) |&gt;\n  ggplot(aes(x     = flipper_length_mm,\n             y     = bill_length_mm,\n             color = sex,\n             size  = body_mass_g)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~species)"
  },
  {
    "objectID": "ml/ml-ops.html#split",
    "href": "ml/ml-ops.html#split",
    "title": "ML Ops with Penguin",
    "section": "Split",
    "text": "Split\n\n# remove rows with missing sex, exclude year and island\npenguins_df &lt;-\n  palmerpenguins::penguins |&gt;\n  drop_na(sex) |&gt;\n  select(-year, -island)\n\n# set the seed for reproducibility\nset.seed(1234)\n\n# Split the data into train and test sets stratified by sex\npenguin_split &lt;- initial_split(penguins_df, strata = sex)\npenguin_train &lt;- training(penguin_split)\npenguin_test  &lt;- testing(penguin_split)\n\n# create folds for cross validation\npenguin_folds &lt;- vfold_cv(penguin_train)"
  },
  {
    "objectID": "ml/ml-ops.html#recipes",
    "href": "ml/ml-ops.html#recipes",
    "title": "ML Ops with Penguin",
    "section": "Recipes",
    "text": "Recipes\n\npenguin_rec &lt;-\n  recipe(sex ~ ., data = penguin_train) |&gt;     \n  step_YeoJohnson(all_numeric_predictors()) |&gt; \n  step_dummy(species) |&gt;                       \n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "ml/ml-ops.html#model-spec",
    "href": "ml/ml-ops.html#model-spec",
    "title": "ML Ops with Penguin",
    "section": "Model Spec",
    "text": "Model Spec\n\n# Logistic Regression\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n# Random Forest\ntree_spec &lt;-\n  rand_forest(min_n = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\n# Neural Network with `{torch}` (Not Done)"
  },
  {
    "objectID": "ml/ml-ops.html#fit-models-tune-hyperparameters",
    "href": "ml/ml-ops.html#fit-models-tune-hyperparameters",
    "title": "ML Ops with Penguin",
    "section": "Fit Models & Tune Hyperparameters",
    "text": "Fit Models & Tune Hyperparameters\nUse Bayes optimizaiton for hyperparameter tuning\n\nbayes_control &lt;- control_bayes(no_improve = 10L,\n                               time_limit = 20,\n                               save_pred  = TRUE,\n                               verbose    = TRUE)\n\n\n# Unix and macOS only\nlibrary(doMC)\n\nLoading required package: foreach\n\n\n\nAttaching package: 'foreach'\n\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nregisterDoMC(cores = 8)\n\n\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(penguin_rec),\n    models  = list(glm   = glm_spec,\n                   tree  = tree_spec)\n  ) |&gt;\n  workflow_map(\"tune_bayes\",\n               iter      = 50L,\n               resamples = penguin_folds,\n               control   = bayes_control\n  )\n\n\n\n\n❯  Generating a set of 5 initial parameter results\n\n\n✓ Initialization complete\n\n\n\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 34 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 33 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 32 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 31 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 30 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 29 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 28 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 27 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 26 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 25 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 24 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\ni Gaussian process model\n\n\n✓ Gaussian process model\n\n\ni Generating 23 candidates\n\n\ni Predicted candidates\n\n\ni Estimating performance\n\n\n✓ Estimating performance\n\n\n! No improvement for 10 iterations; returning current results.\n\nclass(workflow_set)\n\n[1] \"workflow_set\" \"tbl_df\"       \"tbl\"          \"data.frame\"  \n\nworkflow_set\n\n# A workflow set/tibble: 2 × 4\n  wflow_id    info             option    result   \n  &lt;chr&gt;       &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 recipe_glm  &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;rsmp[+]&gt;\n2 recipe_tree &lt;tibble [1 × 4]&gt; &lt;opts[3]&gt; &lt;tune[+]&gt;"
  },
  {
    "objectID": "ml/ml-ops.html#compare-model-results",
    "href": "ml/ml-ops.html#compare-model-results",
    "title": "ML Ops with Penguin",
    "section": "Compare Model Results",
    "text": "Compare Model Results\n\nTabular view\n\n# create table of best models defined using roc_auc metric\nrank_results(workflow_set,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id    .config       .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_glm  Preprocessor… accura… 0.900  0.0199    10 recipe       logi…     1\n2 recipe_glm  Preprocessor… roc_auc 0.969  0.0123    10 recipe       logi…     1\n3 recipe_tree Iter2         accura… 0.912  0.0251    10 recipe       rand…     2\n4 recipe_tree Iter2         roc_auc 0.967  0.0132    10 recipe       rand…     2\n\n\n\n\nPlotting performance\n\nautoplot(workflow_set)"
  },
  {
    "objectID": "ml/ml-ops.html#finalize",
    "href": "ml/ml-ops.html#finalize",
    "title": "ML Ops with Penguin",
    "section": "Finalize",
    "text": "Finalize\n\nSelect best model\n\nbest_model_id &lt;- \"recipe_glm\"\n\nbest_fit &lt;-\n  workflow_set |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\nbest_fit\n\n# A tibble: 1 × 1\n  .config             \n  &lt;chr&gt;               \n1 Preprocessor1_Model1\n\n\n\n\nFinal Fit\n\n# create workflow for best model\nfinal_workflow &lt;-\n  workflow_set |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)\n\n# fit final model with all data\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(penguin_split)\n\n\n\nFinal Metric\n\n# show model performance\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.905 Preprocessor1_Model1\n2 roc_auc  binary         0.971 Preprocessor1_Model1\n\n\n\ncollect_predictions(final_fit) |&gt;\n  roc_curve(sex, .pred_female) |&gt; \n  autoplot()"
  },
  {
    "objectID": "ml/compare-mod.html#data",
    "href": "ml/compare-mod.html#data",
    "title": "Comparing Models",
    "section": "Data",
    "text": "Data\n\ndata(ames)\names &lt;- ames %&gt;% mutate(Sale_Price = log10(Sale_Price))\n\nset.seed(502)\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)\n\names_folds &lt;- vfold_cv(ames_train, v = 10)"
  },
  {
    "objectID": "ml/compare-mod.html#recipes",
    "href": "ml/compare-mod.html#recipes",
    "title": "Comparing Models",
    "section": "Recipes",
    "text": "Recipes\n\nbasic_rec &lt;- \n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n           Latitude + Longitude, data = ames_train) %&gt;%\n  step_log(Gr_Liv_Area, base = 10) %&gt;% \n  step_other(Neighborhood, threshold = 0.01) %&gt;% \n  step_dummy(all_nominal_predictors())\n\ninteraction_rec &lt;- \n  basic_rec %&gt;% \n  step_interact( ~ Gr_Liv_Area:starts_with(\"Bldg_Type_\") ) \n\nspline_rec &lt;- \n  interaction_rec %&gt;% \n  step_ns(Latitude, Longitude, deg_free = 50)\n\n# List of Recipes \npreproc &lt;- \n  list(basic = basic_rec, \n       interact = interaction_rec, \n       splines = spline_rec\n  )"
  },
  {
    "objectID": "ml/compare-mod.html#models",
    "href": "ml/compare-mod.html#models",
    "title": "Comparing Models",
    "section": "Models",
    "text": "Models\n\nmspecs &lt;- list(\n  lm = linear_reg()\n)\n\nclass(mspecs$lm)\n\n[1] \"linear_reg\" \"model_spec\""
  },
  {
    "objectID": "ml/compare-mod.html#workflows",
    "href": "ml/compare-mod.html#workflows",
    "title": "Comparing Models",
    "section": "Workflows",
    "text": "Workflows\n\nlm_models &lt;- workflow_set(preproc, mspecs, cross = FALSE)\nclass(lm_models)\n\n[1] \"workflow_set\" \"tbl_df\"       \"tbl\"          \"data.frame\"  \n\nlm_models\n\n# A workflow set/tibble: 3 × 4\n  wflow_id    info             option    result    \n  &lt;chr&gt;       &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 basic_lm    &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 interact_lm &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 splines_lm  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "ml/compare-mod.html#fit-workflows",
    "href": "ml/compare-mod.html#fit-workflows",
    "title": "Comparing Models",
    "section": "Fit Workflows",
    "text": "Fit Workflows\n\nlm_wfs &lt;- \n  lm_models %&gt;% \n  workflow_map(\"fit_resamples\", \n               # Options to `workflow_map()`: \n               seed = 1101, verbose = TRUE,\n               # Options to `fit_resamples()`: \n               resamples = ames_folds, \n               control = control_resamples(save_pred = T))\n\ni 1 of 3 resampling: basic_lm\n\n\n✔ 1 of 3 resampling: basic_lm (1.8s)\n\n\ni 2 of 3 resampling: interact_lm\n\n\n✔ 2 of 3 resampling: interact_lm (1.8s)\n\n\ni 3 of 3 resampling: splines_lm\n\n\n✔ 3 of 3 resampling: splines_lm (3.2s)\n\nclass(lm_wfs)\n\n[1] \"workflow_set\" \"tbl_df\"       \"tbl\"          \"data.frame\"  \n\nlm_wfs\n\n# A workflow set/tibble: 3 × 4\n  wflow_id    info             option    result   \n  &lt;chr&gt;       &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n1 basic_lm    &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n2 interact_lm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n3 splines_lm  &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;"
  },
  {
    "objectID": "ml/compare-mod.html#metric",
    "href": "ml/compare-mod.html#metric",
    "title": "Comparing Models",
    "section": "Metric",
    "text": "Metric\nMetric for each workflows\n\nlm_wfs_metrics &lt;- collect_metrics(lm_wfs)\nlm_wfs_metrics\n\n# A tibble: 6 × 9\n  wflow_id    .config      preproc model .metric .estimator   mean     n std_err\n  &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 basic_lm    Preprocesso… recipe  line… rmse    standard   0.0804    10 0.00313\n2 basic_lm    Preprocesso… recipe  line… rsq     standard   0.793     10 0.0122 \n3 interact_lm Preprocesso… recipe  line… rmse    standard   0.0800    10 0.00301\n4 interact_lm Preprocesso… recipe  line… rsq     standard   0.795     10 0.0114 \n5 splines_lm  Preprocesso… recipe  line… rmse    standard   0.0786    10 0.00288\n6 splines_lm  Preprocesso… recipe  line… rsq     standard   0.802     10 0.0120"
  },
  {
    "objectID": "ml/tune-mod.html#split",
    "href": "ml/tune-mod.html#split",
    "title": "Tune Models",
    "section": "Split",
    "text": "Split\n\names &lt;- make_ames()\n\nset.seed(4595)\ndata_split &lt;- initial_split(ames, strata = \"Sale_Price\")\n\names_train &lt;- training(data_split)\n\nset.seed(2453)\nrs_splits &lt;- vfold_cv(ames_train, strata = \"Sale_Price\")"
  },
  {
    "objectID": "ml/tune-mod.html#recipes",
    "href": "ml/tune-mod.html#recipes",
    "title": "Tune Models",
    "section": "Recipes",
    "text": "Recipes\n\names_rec &lt;-\n  recipe(Sale_Price ~ ., data = ames_train) %&gt;%\n  step_log(Sale_Price, base = 10) %&gt;%\n  step_YeoJohnson(Lot_Area, Gr_Liv_Area) %&gt;%\n  step_other(Neighborhood, threshold = .1)  %&gt;%\n  step_dummy(all_nominal()) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_ns(Longitude, deg_free = tune(\"lon\")) %&gt;%\n  step_ns(Latitude, deg_free = tune(\"lat\"))"
  },
  {
    "objectID": "ml/tune-mod.html#models",
    "href": "ml/tune-mod.html#models",
    "title": "Tune Models",
    "section": "Models",
    "text": "Models\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\"),\n    weight_func = tune(),\n    dist_power = tune()\n  ) %&gt;%\n  set_engine(\"kknn\")"
  },
  {
    "objectID": "ml/tune-mod.html#workflow-parameters",
    "href": "ml/tune-mod.html#workflow-parameters",
    "title": "Tune Models",
    "section": "Workflow & Parameters",
    "text": "Workflow & Parameters\n\names_wflow &lt;-\n  workflow() %&gt;%\n  add_recipe(ames_rec) %&gt;%\n  add_model(knn_model)\n\nclass(ames_wflow)\n\n[1] \"workflow\"\n\n\n\names_set &lt;-\n  extract_parameter_set_dials(ames_wflow) %&gt;%\n  update(K = neighbors(c(1, 50)))\n\nclass(ames_set)\n\n[1] \"parameters\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\names_set\n\nCollection of 5 parameters for tuning\n\n  identifier        type    object\n           K   neighbors nparam[+]\n weight_func weight_func dparam[+]\n  dist_power  dist_power nparam[+]\n         lon    deg_free nparam[+]\n         lat    deg_free nparam[+]"
  },
  {
    "objectID": "ml/tune-mod.html#grid",
    "href": "ml/tune-mod.html#grid",
    "title": "Tune Models",
    "section": "Grid",
    "text": "Grid\n\nParameter Grids\n\nset.seed(7014)\n\n### Space-filling parameter grids\names_grid &lt;-\n  ames_set %&gt;%\n  grid_max_entropy(size = 10)\n\names_grid\n\n# A tibble: 10 × 5\n       K weight_func  dist_power   lon   lat\n   &lt;int&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n 1    35 optimal           1.32      8     1\n 2    35 rank              1.29      3    13\n 3    21 cos               0.626     1     4\n 4     4 biweight          0.311     8     4\n 5    32 triangular        0.165     9    15\n 6     3 rank              1.86     10    15\n 7    40 triangular        0.167    11     7\n 8    12 epanechnikov      1.53      4     7\n 9     5 rank              0.411     2     7\n10    33 triweight         0.511    10     3\n\n\n\n\nGrid Search !\n### Perform Grid Search (Not Run)\n\names_grid_search &lt;-\n  tune_grid(\n    ames_wflow,\n    resamples = rs_splits,\n    grid = ames_grid\n  )\n\ndata(\"example_ames_knn\")\nclass(ames_grid_search)\n\n[1] \"tune_results\" \"tbl_df\"       \"tbl\"          \"data.frame\"  \n\names_grid_search\n\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [1978/0]&gt; Fold01 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 2 &lt;split [1979/0]&gt; Fold02 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 3 &lt;split [1979/0]&gt; Fold03 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 4 &lt;split [1979/0]&gt; Fold04 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 5 &lt;split [1979/0]&gt; Fold05 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 6 &lt;split [1979/0]&gt; Fold06 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 7 &lt;split [1979/0]&gt; Fold07 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 8 &lt;split [1979/0]&gt; Fold08 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n 9 &lt;split [1979/0]&gt; Fold09 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;\n10 &lt;split [1981/0]&gt; Fold10 &lt;tibble [20 × 9]&gt; &lt;tibble [0 × 1]&gt;"
  },
  {
    "objectID": "ml/tune-mod.html#finalized",
    "href": "ml/tune-mod.html#finalized",
    "title": "Tune Models",
    "section": "Finalized",
    "text": "Finalized\n\nSelect Best Tune Result\n\nlowest_rmse &lt;- select_best(ames_grid_search, metric = \"rmse\")\nclass(lowest_rmse)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nlowest_rmse\n\n# A tibble: 1 × 6\n      K weight_func dist_power   lon   lat .config              \n  &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1    33 triweight        0.511    10     3 Preprocessor10_Model1\n\n\n\n\nLast Fit\n\names_res_last &lt;- workflow(ames_rec, knn_model) |&gt; \n  finalize_workflow(lowest_rmse) |&gt; \n  last_fit(split = data_split, metrics = metric_set(rmse))\n\n\nclass(ames_res_last)\n\n[1] \"last_fit\"         \"resample_results\" \"tune_results\"     \"tbl_df\"          \n[5] \"tbl\"              \"data.frame\"      \n\names_res_last\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [2197/733]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;"
  },
  {
    "objectID": "misc/parallel.html#parallel",
    "href": "misc/parallel.html#parallel",
    "title": "Parallel Processing",
    "section": "{parallel}",
    "text": "{parallel}\n\n# The number of physical cores in the hardware:\nparallel::detectCores(logical = FALSE)\n\n[1] 4\n\n# The number of possible independent processes that can \n# be simultaneously used:  \nparallel::detectCores(logical = TRUE)\n\n[1] 8"
  },
  {
    "objectID": "misc/parallel.html#domc",
    "href": "misc/parallel.html#domc",
    "title": "Parallel Processing",
    "section": "{doMC}",
    "text": "{doMC}\n\n# Unix and macOS only\nlibrary(doMC)\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\nregisterDoMC(cores = 8)\n\n# Now run fit_resamples()...\n\nregisterDoSEQ() # Reset"
  },
  {
    "objectID": "misc/parallel.html#doparallel",
    "href": "misc/parallel.html#doparallel",
    "title": "Parallel Processing",
    "section": "{doParallel}",
    "text": "{doParallel}\n\n# All operating systems\nlibrary(doParallel)\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(8)\nregisterDoParallel(cl)\n\n## Run\n\n# Reset\nstopCluster(cl)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  }
]
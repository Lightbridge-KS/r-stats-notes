[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stats & ML Notes",
    "section": "",
    "text": "About\n\n\n\nThis is my notes on statistics and machine learning using R."
  },
  {
    "objectID": "stats/normality-test.html",
    "href": "stats/normality-test.html",
    "title": "Normality Test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rstatix)\nlibrary(ggpubr)\nReferences"
  },
  {
    "objectID": "stats/normality-test.html#explore-data",
    "href": "stats/normality-test.html#explore-data",
    "title": "Normality Test",
    "section": "Explore Data",
    "text": "Explore Data\n\nglimpse(ToothGrowth)\n#> Rows: 60\n#> Columns: 3\n#> $ len  <dbl> 4.2, 11.5, 7.3, 5.8, 6.4, 10.0, 11.2, 11.2, 5.2, 7.0, 16.5, 16.5,…\n#> $ supp <fct> VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, VC, V…\n#> $ dose <dbl> 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, …\n\n\nskimr::skim(ToothGrowth)\n\n\nData summary\n\n\nName\nToothGrowth\n\n\nNumber of rows\n60\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsupp\n0\n1\nFALSE\n2\nOJ: 30, VC: 30\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlen\n0\n1\n18.81\n7.65\n4.2\n13.07\n19.25\n25.27\n33.9\n▅▃▅▇▂\n\n\ndose\n0\n1\n1.17\n0.63\n0.5\n0.50\n1.00\n2.00\n2.0\n▇▇▁▁▇"
  },
  {
    "objectID": "stats/normality-test.html#normality-check",
    "href": "stats/normality-test.html#normality-check",
    "title": "Normality Test",
    "section": "Normality Check",
    "text": "Normality Check\n\n\n\n\n\n\nObjective\n\n\n\nWe want to test if the variable len (tooth length) is normally distributed."
  },
  {
    "objectID": "stats/normality-test.html#visual-method",
    "href": "stats/normality-test.html#visual-method",
    "title": "Normality Test",
    "section": "Visual Method",
    "text": "Visual Method\n\nHistogram\n\nToothGrowth %>% \n  ggplot(aes(len)) +\n  geom_histogram()\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nDensity\n\nggdensity(ToothGrowth$len, fill = \"lightgray\")\n\n\n\n\n\n\nQQ Plot\n\nggqqplot(ToothGrowth$len)\n\n\n\n\n\nToothGrowth %>% \n  ggplot(aes(sample = len)) +\n  geom_qq() +\n  geom_qq_line()"
  },
  {
    "objectID": "stats/normality-test.html#shapiro-wilks-normality-test",
    "href": "stats/normality-test.html#shapiro-wilks-normality-test",
    "title": "Normality Test",
    "section": "Shapiro-Wilk’s normality test",
    "text": "Shapiro-Wilk’s normality test\n\n\n\n\n\n\nHypothesis\n\n\n\n\\(H_0\\) = “sample distribution is normal”\n\n\n\nOne Variable\n\nshapiro.test(ToothGrowth$len)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  ToothGrowth$len\n#> W = 0.96743, p-value = 0.1091\n\nOr\n\nToothGrowth %>% shapiro_test(len)\n#> # A tibble: 1 × 3\n#>   variable statistic     p\n#>   <chr>        <dbl> <dbl>\n#> 1 len          0.967 0.109\n\nP-value > 0.05; implying that the distribution of the data are not significantly different from normal distribution; therefore, we can assume normality.\n\n\nGrouped Data\n\nToothGrowth %>%\n  group_by(dose) %>%\n  shapiro_test(len)\n#> # A tibble: 3 × 4\n#>    dose variable statistic     p\n#>   <dbl> <chr>        <dbl> <dbl>\n#> 1   0.5 len          0.941 0.247\n#> 2   1   len          0.931 0.164\n#> 3   2   len          0.978 0.902"
  },
  {
    "objectID": "stats/infer.html",
    "href": "stats/infer.html",
    "title": "Infer Package Intro",
    "section": "",
    "text": "I will explore {infer} Package."
  },
  {
    "objectID": "stats/infer.html#explore-data",
    "href": "stats/infer.html#explore-data",
    "title": "Infer Package Intro",
    "section": "Explore Data",
    "text": "Explore Data\n\nglimpse(gss)\n#> Rows: 500\n#> Columns: 11\n#> $ year    <dbl> 2014, 1994, 1998, 1996, 1994, 1996, 1990, 2016, 2000, 1998, 20…\n#> $ age     <dbl> 36, 34, 24, 42, 31, 32, 48, 36, 30, 33, 21, 30, 38, 49, 25, 56…\n#> $ sex     <fct> male, female, male, male, male, female, female, female, female…\n#> $ college <fct> degree, no degree, degree, no degree, degree, no degree, no de…\n#> $ partyid <fct> ind, rep, ind, ind, rep, rep, dem, ind, rep, dem, dem, ind, de…\n#> $ hompop  <dbl> 3, 4, 1, 4, 2, 4, 2, 1, 5, 2, 4, 3, 4, 4, 2, 2, 3, 2, 1, 2, 5,…\n#> $ hours   <dbl> 50, 31, 40, 40, 40, 53, 32, 20, 40, 40, 23, 52, 38, 72, 48, 40…\n#> $ income  <ord> $25000 or more, $20000 - 24999, $25000 or more, $25000 or more…\n#> $ class   <fct> middle class, working class, working class, working class, mid…\n#> $ finrela <fct> below average, below average, below average, above average, ab…\n#> $ weight  <dbl> 0.8960034, 1.0825000, 0.5501000, 1.0864000, 1.0825000, 1.08640…"
  },
  {
    "objectID": "stats/infer.html#specifying-response-specify",
    "href": "stats/infer.html#specifying-response-specify",
    "title": "Infer Package Intro",
    "section": "Specifying Response specify()",
    "text": "Specifying Response specify()\nSpecify response and explanatory variable as formula or arguments.\n\nContinuous Response\nage (num) ~ partyid (fct)\n\ngss_spec_age_partyid <- gss %>% \n  specify(age ~ partyid)\n#> Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n\n# Object Type\nsloop::otype(gss_spec_age_partyid)\n#> [1] \"S3\"\n# Class\nclass(gss_spec_age_partyid)\n#> [1] \"infer\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n# Print\ngss_spec_age_partyid\n#> Response: age (numeric)\n#> Explanatory: partyid (factor)\n#> # A tibble: 500 × 2\n#>      age partyid\n#>    <dbl> <fct>  \n#>  1    36 ind    \n#>  2    34 rep    \n#>  3    24 ind    \n#>  4    42 ind    \n#>  5    31 rep    \n#>  6    32 rep    \n#>  7    48 dem    \n#>  8    36 ind    \n#>  9    30 rep    \n#> 10    33 dem    \n#> # … with 490 more rows\n\n\n\nCategorical Response\nspecifying for inference on proportions\nyou will need to use the success argument to specify which level of your response variable is a success.\n\ngss %>%\n  specify(response = college, success = \"degree\")\n#> Response: college (factor)\n#> # A tibble: 500 × 1\n#>    college  \n#>    <fct>    \n#>  1 degree   \n#>  2 no degree\n#>  3 degree   \n#>  4 no degree\n#>  5 degree   \n#>  6 no degree\n#>  7 no degree\n#>  8 degree   \n#>  9 degree   \n#> 10 no degree\n#> # … with 490 more rows"
  },
  {
    "objectID": "stats/infer.html#declare-the-null-hypothesis",
    "href": "stats/infer.html#declare-the-null-hypothesis",
    "title": "Infer Package Intro",
    "section": "Declare the NULL Hypothesis",
    "text": "Declare the NULL Hypothesis\ndeclare a null hypothesis using hypothesize().\nnull: “independence” or “point”.\n\nTest Independence\nIf the null hypothesis is that the mean number of hours worked per week in our population is 40, we would write:\n\ngss %>%\n  specify(college ~ partyid, success = \"degree\") %>%\n  hypothesize(null = \"independence\")\n#> Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n#> Response: college (factor)\n#> Explanatory: partyid (factor)\n#> Null Hypothesis: independence\n#> # A tibble: 500 × 2\n#>    college   partyid\n#>    <fct>     <fct>  \n#>  1 degree    ind    \n#>  2 no degree rep    \n#>  3 degree    ind    \n#>  4 no degree ind    \n#>  5 degree    rep    \n#>  6 no degree rep    \n#>  7 no degree dem    \n#>  8 degree    ind    \n#>  9 degree    rep    \n#> 10 no degree dem    \n#> # … with 490 more rows\n\n\n\nTest Point Estimate\n\ngss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40)\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 500 × 1\n#>    hours\n#>    <dbl>\n#>  1    50\n#>  2    31\n#>  3    40\n#>  4    40\n#>  5    40\n#>  6    53\n#>  7    32\n#>  8    20\n#>  9    40\n#> 10    40\n#> # … with 490 more rows"
  },
  {
    "objectID": "stats/infer.html#generate-null-distribution",
    "href": "stats/infer.html#generate-null-distribution",
    "title": "Infer Package Intro",
    "section": "generate() NULL distribution",
    "text": "generate() NULL distribution\n\nset.seed(1)\n\ngss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40) %>%\n  generate(reps = 1000, type = \"bootstrap\")\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 500,000 × 2\n#> # Groups:   replicate [1,000]\n#>    replicate hours\n#>        <int> <dbl>\n#>  1         1 46.6 \n#>  2         1 43.6 \n#>  3         1 38.6 \n#>  4         1 28.6 \n#>  5         1 38.6 \n#>  6         1 38.6 \n#>  7         1  6.62\n#>  8         1 78.6 \n#>  9         1 38.6 \n#> 10         1 38.6 \n#> # … with 499,990 more rows"
  },
  {
    "objectID": "stats/infer.html#calculate-summary-stats",
    "href": "stats/infer.html#calculate-summary-stats",
    "title": "Infer Package Intro",
    "section": "Calculate Summary Stats",
    "text": "Calculate Summary Stats\nfind the point estimate\n\nobs_mean <- gss %>%\n  specify(response = hours) %>%\n  calculate(stat = \"mean\")\n\nobs_mean\n#> Response: hours (numeric)\n#> # A tibble: 1 × 1\n#>    stat\n#>   <dbl>\n#> 1  41.4\n\ngenerate a null distribution\n\nnull_dist <- gss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40) %>%\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\n\nnull_dist\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 1,000 × 2\n#>    replicate  stat\n#>        <int> <dbl>\n#>  1         1  40.5\n#>  2         2  40.1\n#>  3         3  39.1\n#>  4         4  40.3\n#>  5         5  38.8\n#>  6         6  39.6\n#>  7         7  40.2\n#>  8         8  40.4\n#>  9         9  40.1\n#> 10        10  40.6\n#> # … with 990 more rows"
  },
  {
    "objectID": "stats/infer.html#visualize-null-dist",
    "href": "stats/infer.html#visualize-null-dist",
    "title": "Infer Package Intro",
    "section": "Visualize Null Dist",
    "text": "Visualize Null Dist\n\nnull_dist %>%\n  visualize()\n\n\n\n\nWhere does our sample’s observed statistic lie on this distribution? We can use the obs_stat argument to specify this.\n\nnull_dist %>%\n  visualize() +\n  shade_p_value(obs_stat = obs_mean, direction = \"two-sided\")"
  },
  {
    "objectID": "stats/infer.html#p-value",
    "href": "stats/infer.html#p-value",
    "title": "Infer Package Intro",
    "section": "P-value",
    "text": "P-value\nget a two-tailed p-value\n\np_value <- null_dist %>%\n  get_p_value(obs_stat = obs_mean, direction = \"two-sided\")\n\np_value\n#> # A tibble: 1 × 1\n#>   p_value\n#>     <dbl>\n#> 1   0.038"
  },
  {
    "objectID": "stats/infer.html#confidence-interval",
    "href": "stats/infer.html#confidence-interval",
    "title": "Infer Package Intro",
    "section": "Confidence Interval",
    "text": "Confidence Interval\n\n# generate a distribution like the null distribution, \n# though exclude the null hypothesis from the pipeline\nboot_dist <- gss %>%\n  specify(response = hours) %>%\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\n\n# start with the bootstrap distribution\nci <- boot_dist %>%\n  # calculate the confidence interval around the point estimate\n  get_confidence_interval(point_estimate = obs_mean,\n                          # at the 95% confidence level\n                          level = .95,\n                          # using the standard error\n                          type = \"se\")\n\nci\n#> # A tibble: 1 × 2\n#>   lower_ci upper_ci\n#>      <dbl>    <dbl>\n#> 1     40.1     42.7\n\n\nboot_dist %>%\n  visualize() +\n  shade_confidence_interval(endpoints = ci)"
  },
  {
    "objectID": "stats/wilcoxon.html",
    "href": "stats/wilcoxon.html",
    "title": "Wilcoxon Test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rstatix)\nlibrary(ggpubr)\nReferences:"
  },
  {
    "objectID": "stats/wilcoxon.html#introduction",
    "href": "stats/wilcoxon.html#introduction",
    "title": "Wilcoxon Test",
    "section": "Introduction",
    "text": "Introduction\n\nThe Wilcoxon test is a non-parametric test for comparing 2 groups\nLess powerful than t-test, i.e., more likely to fail to reject the \\(H_0\\) that there is no difference.\n\n\n\n\n\n\n\nWhen to use\n\n\n\nData is not normally distributed and the sample size is small (n < 30) (so that central limit theorem not applied)"
  },
  {
    "objectID": "stats/wilcoxon.html#wilcoxon-signed-rank-test-on-paired-samples",
    "href": "stats/wilcoxon.html#wilcoxon-signed-rank-test-on-paired-samples",
    "title": "Wilcoxon Test",
    "section": "Wilcoxon signed rank test on paired samples",
    "text": "Wilcoxon signed rank test on paired samples\n\nData\n\n# Wide format\ndata(\"mice2\", package = \"datarium\")\nhead(mice2, 3)\n#>   id before after\n#> 1  1  187.2 429.5\n#> 2  2  194.2 404.4\n#> 3  3  231.7 405.6\n\nTransform to long\n\nmice2.long <- mice2 %>%\n  gather(key = \"group\", value = \"weight\", before, after)\n\nhead(mice2.long, 3)\n#>   id  group weight\n#> 1  1 before  187.2\n#> 2  2 before  194.2\n#> 3  3 before  231.7\n\n\n\nSummary Stats\n\nmice2.long %>%\n  group_by(group) %>%\n  get_summary_stats(weight, type = \"median_iqr\")\n#> # A tibble: 2 × 5\n#>   group  variable     n median   iqr\n#>   <chr>  <chr>    <dbl>  <dbl> <dbl>\n#> 1 after  weight      10   405   28.3\n#> 2 before weight      10   197.  19.2\n\n\nggpaired(mice2.long, x = \"group\", y = \"weight\", \n         order = c(\"before\", \"after\"),\n         ylab = \"Weight\", xlab = \"Groups\")\n\n\n\n\nThe test assumes that differences between paired samples should be distributed symmetrically around the median.\n\nmice2d <- mice2 %>% \n  mutate(differences = after - before)\n\ngghistogram(mice2d, x = \"differences\", y = \"..density..\", \n            fill = \"steelblue\",bins = 5, add_density = TRUE)\n\n\n\n\n\n\nComputation\n\nwilcox.test(weight ~ group, data = mice2.long, paired = TRUE)\n#> \n#>  Wilcoxon signed rank exact test\n#> \n#> data:  weight by group\n#> V = 55, p-value = 0.001953\n#> alternative hypothesis: true location shift is not equal to 0\n\nOr\n\nstat.test <- mice2.long  %>%\n  wilcox_test(weight ~ group, paired = TRUE) %>%\n  add_significance()\n\nstat.test\n#> # A tibble: 1 × 8\n#>   .y.    group1 group2    n1    n2 statistic       p p.signif\n#> * <chr>  <chr>  <chr>  <int> <int>     <dbl>   <dbl> <chr>   \n#> 1 weight after  before    10    10        55 0.00195 **\n\n\n\nEffect size\n\nmice2.long  %>%\n  wilcox_effsize(weight ~ group, paired = TRUE)\n#> # A tibble: 1 × 7\n#>   .y.    group1 group2 effsize    n1    n2 magnitude\n#> * <chr>  <chr>  <chr>    <dbl> <int> <int> <ord>    \n#> 1 weight after  before   0.886    10    10 large\n\n\n\nViz ggplot2\n\nmice2.long %>% \n  ggplot(aes(group, weight, color = group, fill = group)) +\n  geom_boxplot(alpha = 0.4) +\n  geom_jitter() +\n  ggpubr::stat_compare_means(method = \"wilcox.test\",\n                             paired = TRUE, \n                             label.x = 1.5, \n                             label.y = 450, \n                             show.legend = F)\n\n\n\n\n\n\nViz: {ggstatsplot}\n\nlibrary(ggstatsplot)\n\n\nset.seed(123) # Seed for bootstraped CI\n\nggwithinstats( # paired samples\n  data = mice2.long,\n  x = group,\n  y = weight,\n  type = \"nonparametric\", # for wilcoxon\n  centrality.plotting = FALSE # remove median\n)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  }
]
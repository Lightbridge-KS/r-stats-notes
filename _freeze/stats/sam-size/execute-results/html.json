{
  "hash": "45ee2c28a90943c976c43efb4787b945",
  "result": {
    "markdown": "---\ntitle: \"Sample Size (Traditional)\"\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\nlibrary(WebPower)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: MASS\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lme4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lavaan\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is lavaan 0.6-16\nlavaan is FREE software! Please report any bugs.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: parallel\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: PearsonDS\n```\n:::\n\n```{.r .cell-code}\nlibrary(simstudy)\n```\n:::\n\n\n-   [Sample Size in R (Slide)](https://med.und.edu/research/daccota/_files/pdfs/berdc_resource_pdfs/sample_size_r_module.pdf)\n\n## Overview\n\n![Packages for Sample Size](/pic/sample-size/sample-size-pkg.png)\n\n\n![Functions & packages for Sample Size](/pic/sample-size/sample-size-pkg-2.png)\n\n### Typical Values\n\n- A two-tailed test\n- a significance of **0.05** and a power of **80%** was established. \n\n- For **nonparametric tests** on continuous variables, as a rule of thumb, calculate the sample size required for parametric tests and **add 15%**\n\n### Effect Size\n\n- Effect size can be defined as ‘a standardized measure of the magnitude of the mean difference or relationship between study groups’\n\n- An index that divides the effect size by its dispersion (standard deviation, etc.) is not affected by the measurement unit and can be used regardless of the unit, and is called an ‘effect size index’ or ‘standardized effect size\n\n- Whether an effect size should be interpreted as small, medium, or large may depend on the analysis method. \n\n- We use the guidelines mentioned by Cohen and Sawilowsky and use the medium effect size considered for each test in the examples below.\n\n### Conventional Effect Size\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohen.ES(test = \"t\", size = \"medium\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Conventional effect size from Cohen (1982) \n\n           test = t\n           size = medium\n    effect.size = 0.5\n```\n:::\n:::\n\n\n## Two Means T-test\n\ntests if a mean from one group is different from the mean of another group for a normally distributed variable. AKA, testing to see if the difference in means is different from zero.\n\n**Effect size for t-test:** 0.2 = small, 0.5 = medium, 0.8 = large effect sizes\n\n$$\nd = \\frac{\\mu_1 - \\mu_2}{s_{pooled}}\n$$ The pooled standard deviation ( $s_{pooled}$ ) is calculated as:\n\n$$\ns\\_{pooled} = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}} \n$$ \\### Ex 1: Caloric Intake\n\n#### Find N\n\nYou are interested in determining if the average daily caloric intake different between men and women. You collected trial data and found the:\n\n-   average caloric intake for males to be 2350.2 (SD=258)\n-   females had intake of 1872.4 (SD=420).\n\n(Don't know N for each group)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd_pooled_1 <- sqrt((258^2 + 420^2)/2)\nsd_pooled_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 348.5427\n```\n:::\n\n```{.r .cell-code}\neff_size1 <- (2350.2 - 1872.4) / sd_pooled_1\neff_size1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.370851\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(d = eff_size1, \n           sig.level=0.05, \n           power=0.80, type= \"two.sample\", alternative=\"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 9.417703\n              d = 1.370851\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n#### Simulate\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndef_1 <- simstudy::defData(\n  varname = \"intake_male\", formula = 2350.2,\n  variance = 258^2\n) |>\n  simstudy::defData(\n    varname = \"intake_female\", formula = 1872.4,\n    variance = 420^2\n  )\n\nset.seed(123)\ndf_intake <- genData(n = 10, def_1) |> \n  pivot_longer(cols = starts_with(\"intake\"), names_to = \"gender\", \n               values_to = \"intake\", names_prefix = \"intake_\") |> \n  dplyr::select(-id)\n\ndf_intake |> \n  group_by(gender) |> \n  rstatix::get_summary_stats(type = \"mean_sd\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  gender variable     n  mean    sd\n  <chr>  <fct>    <dbl> <dbl> <dbl>\n1 female intake      10 1960.  436.\n2 male   intake      10 2369.  246.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrstatix::t_test(df_intake, intake ~ gender) # Sig\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n  .y.    group1 group2    n1    n2 statistic    df      p\n* <chr>  <chr>  <chr>  <int> <int>     <dbl> <dbl>  <dbl>\n1 intake female male      10    10     -2.59  14.2 0.0214\n```\n:::\n:::\n\n\n### Ex 2\n\nYou are interested in determining if the average protein level in blood different between men and women. You collected the following trial data on protein level (grams/deciliter).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprot_samp <- data.frame(\n  gender = c(rep(\"M\", 8), rep(\"F\", 8)),\n  prot = c(\n    c(1.8, 5.8, 7.1, 4.6, 5.5, 2.4, 8.3, 1.2), # Male\n    c(9.5, 2.6, 3.7, 4.7, 6.4, 8.4, 3.1, 1.4) # Female\n  )\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprot_samp |> \n  group_by(gender) |> \n  summarise(mean = mean(prot), sd = sd(prot))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  gender  mean    sd\n  <chr>  <dbl> <dbl>\n1 F       4.98  2.88\n2 M       4.59  2.58\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size2 <- (4.9750 - 4.5875\t) / sqrt((2.875388^2 + 2.575399^2) / 2)\neff_size2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1419665\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(d = eff_size2, sig.level=0.05, \n           power=0.80, type= \"two.sample\", alternative=\"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 779.8317\n              d = 0.1419665\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n## ANOVA\n\n### Effect Size of ANOVA (f)\n\n```         \nPartial Eta Squared (η2) = SStreat / SStotal\n```\n\n```         \nf = √((η2 /(1- η2)\n```\n\n**Total Sum of Squares (SStotal):**\n\n$$\n\\text{SStotal} = \\sum (Y_i - \\bar{Y})^2\n$$\n\nwhere ( $Y_i$ ) are the individual data points and ( $\\bar{Y}$ ) is the overall mean.\n\n**Treatment Sum of Squares (SStreat):**\n\n$$\n\\text{SStreat} = \\sum n_j (\\bar{Y}_j - \\bar{Y})^2\n$$\n\nwhere ( $n_j$ ) is the number of observations in each group, ( $\\bar{Y}_j$ ) is the mean of each group, and ( $\\bar{Y}$ ) is the overall mean.\n\n### Ex 1: Sx Option\n\nYou are interested in determining there is a difference in weight lost between 4 different surgery options. You collect the following trial data of weight lost in pounds\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsx_opt <- data.frame(\n  op1 = c(6.3, 2.8, 7.8, 7.9, 4.9),\n  op2 = c(9.9, 4.1, 3.9, 6.3, 6.9),\n  op3 = c(5.1, 2.9, 3.6, 5.7, 4.5),\n  op4 = c(1, 2.8, 4.8, 3.9, 1.6)\n) |> \n  pivot_longer(cols = everything(), names_to = \"op\", values_to = \"wt_loss\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsx_opt_aov <- aov(wt_loss ~ op, data = sx_opt)\nsx_opt_aov_tbl <- summary(sx_opt_aov)\nsx_opt_aov_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)  \nop           3  37.13  12.375    3.46 0.0414 *\nResiduals   16  57.22   3.576                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n#### SStreat\n\n$$\n\\text{SStreat} = \\sum n_j (\\bar{Y}_j - \\bar{Y})^2\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSStreat <- sx_opt_aov_tbl[[1]][\"op\", \"Sum Sq\"]\nSStreat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37.1255\n```\n:::\n:::\n\n\nOr\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsx_opt |> \n  group_by(op) |> \n  summarise(mean_gr = mean(wt_loss), n = n()) |> \n  mutate(SStx_gr = n * (mean_gr - mean(sx_opt$wt_loss))^2) |> \n  summarise(SStx = sum(SStx_gr))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n   SStx\n  <dbl>\n1  37.1\n```\n:::\n:::\n\n\n#### SStotal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSStotal <- sum((sx_opt$wt_loss - mean(sx_opt$wt_loss))^2)\nSStotal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 94.3455\n```\n:::\n:::\n\n\nOr\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSStotal <- sum(sx_opt_aov_tbl[[1]][, \"Sum Sq\"])\nSStotal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 94.3455\n```\n:::\n:::\n\n\n#### Effect Size (f)\n\n```         \nPartial Eta Squared (η2) = SStreat / SStotal\n```\n\n```         \nf = √((η2 /(1- η2)\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_squared <- SStreat / SStotal\neff_size3 <- sqrt(n_squared / (1 - n_squared))\neff_size3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8054939\n```\n:::\n:::\n\n\n#### Find N\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.anova.test(k = 4, f = eff_size3, sig.level=0.05, power =0.80 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 5.287432\n              f = 0.8054939\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n```\n:::\n:::\n\n\n## Two Prop\n\n### Ex 1: Stat Scores\n\nYou are interested in determining if the expected proportion (P1) of students passing a stats course taught by psychology teachers is different than the observed proportion (P2) of students passing the same stats class taught by biology teachers. You collected the following data of passed tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstat_course <- data.frame(\n  Psychology = c(\"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\"),\n  Biology = c(\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\")\n) \n\ntable(stat_course$Psychology, stat_course$Biology)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     \n      No Yes\n  No   0   3\n  Yes  4   3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- (4 + 3) / 10\np2 <-  (3 + 3) / 10\n\neff_size4 = 2*asin(sqrt(p2))-2*asin(sqrt(p1))\neff_size4\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2101589\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.2p.test(h= eff_size4, sig.level=0.05, power=0.80,\n            alternative=\"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2101589\n              n = 355.4193\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n```\n:::\n:::\n\n\n## Chi-Squared\n\n**Description:** Extension of proportions test, which asks if table of observed values are any different from a table of expected ones. Also called Goodness-of-fit test.\n\n### Ex 1\n\nYou are interested in determining if the ethnic ratios in a company differ by gender. You collect the following trial data from 200 employees.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemployee <- data.frame(\n  male = c(rep(\"White\", 0.6 * 100), rep(\"Black\", 0.25 * 100), \n           rep(\"Am\", 0.01 * 100), rep(\"Asian\", 0.14 * 100)),\n  female = c(rep(\"White\", 0.65 * 100), rep(\"Black\", 0.21 * 100), \n           rep(\"Am\", 0.11 * 100), rep(\"Asian\", 0.03 * 100))\n) |> \n  pivot_longer(cols = everything(),\n               names_to = \"gender\", values_to = \"ethnic\") \n\nemployee\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 200 × 2\n   gender ethnic\n   <chr>  <chr> \n 1 male   White \n 2 female White \n 3 male   White \n 4 female White \n 5 male   White \n 6 female White \n 7 male   White \n 8 female White \n 9 male   White \n10 female White \n# ℹ 190 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(employee$gender, employee$ethnic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        \n         Am Asian Black White\n  female 11     3    21    65\n  male    1    14    25    60\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nemployee_chisq <- chisq.test(table(employee$gender, employee$ethnic))\nemployee_chisq\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  table(employee$gender, employee$ethnic)\nX-squared = 15.999, df = 3, p-value = 0.001135\n```\n:::\n:::\n\n\n$$\nw = \\sqrt{ \\frac{ \\chi_{2} }{ n \\times df }}\n$$\n\nX2= Chi-squared = ∑(O-E)2/E\n\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size5 <- sqrt( unname(employee_chisq$statistic) / (200 * (4 - 1)))\npwr.chisq.test(eff_size5,  df=3, sig.level=0.05, power=0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Chi squared power calculation \n\n              w = 0.1632932\n              N = 408.8766\n             df = 3\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: N is the number of observations\n```\n:::\n:::\n\n\n## Simple Linear Reg\n\n### Ex 1\n\nYou are interested in determining if height (meters) in plants can predict yield (grams of berries). You collect the following trial data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_yield <- data.frame(\n  yield = c(46.8, 48.7, 48.4, 53.7, 56.7),\n  height = c(14.6, 19.6, 18.6, 25.5, 20.4)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_yield_lmsum <- lm(height ~ yield, data = plant_yield) |> summary()\nplant_yield_lmsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = height ~ yield, data = plant_yield)\n\nResiduals:\n     1      2      3      4      5 \n-2.554  1.236  0.427  3.951 -3.060 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept) -12.6564    20.3700  -0.621    0.578\nyield         0.6370     0.3994   1.595    0.209\n\nResidual standard error: 3.327 on 3 degrees of freedom\nMultiple R-squared:  0.4588,\tAdjusted R-squared:  0.2784 \nF-statistic: 2.543 on 1 and 3 DF,  p-value: 0.2091\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size6 <- sqrt(plant_yield_lmsum$adj.r.squared)\n\npwr.f2.test(u=1, f2=eff_size6, sig.level=0.05, power=0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 15.02932\n             f2 = 0.5275993\n      sig.level = 0.05\n          power = 0.8\n```\n:::\n:::\n\n\n-  `u` = numerator degrees of freedom (n_vars - 1)\n-  `v` = denominator degrees of freedom\n-  `f2` = effect size\n\nSample Size = `v` + n_vars\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# N\nceiling(15.02932) + 2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18\n```\n:::\n:::\n\n\n### Ex 2 (No Prior)\n\nYou are interested in determining if the size of a city (in square miles) can predict the population of the city (in # of individuals).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohen.ES(test = \"f2\", size = \"large\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Conventional effect size from Cohen (1982) \n\n           test = f2\n           size = large\n    effect.size = 0.35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.f2.test(u = 1, \n            f2 = 0.35,  \n            sig.level=0.05, power=0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 22.50313\n             f2 = 0.35\n      sig.level = 0.05\n          power = 0.8\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# N\nceiling(22.50313) + 2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 25\n```\n:::\n:::\n\n\n## Multiple Linear Reg\n\n### Ex 1\n\nYou are interested in determining if height (meters), weight (grams), and fertilizer added (grams) in plants can predict yield (grams of berries). You collect the following trial data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_yield2 <- data.frame(\n  yield = c(46.8, 48.7, 48.4, 53.7, 56.7),\n  height = c(14.6, 19.6, 18.6, 25.5, 20.4),\n  weight = c(95.3, 99.5, 94.1, 110, 103),\n  Fert = c(2.1, 3.2, 4.3, 1.1, 4.3)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_yield2_lmsum <- lm(height~yield + weight + Fert, \n                         data = plant_yield2) |> summary()\nplant_yield2_lmsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = height ~ yield + weight + Fert, data = plant_yield2)\n\nResiduals:\n      1       2       3       4       5 \n-0.4799 -1.2588  1.5100  0.7626 -0.5340 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept) -64.2253    30.2429  -2.124    0.280\nyield        -0.7999     0.7948  -1.006    0.498\nweight        1.1779     0.5988   1.967    0.299\nFert          2.1379     1.8204   1.174    0.449\n\nResidual standard error: 2.227 on 1 degrees of freedom\nMultiple R-squared:  0.9191,\tAdjusted R-squared:  0.6765 \nF-statistic: 3.788 on 3 and 1 DF,  p-value: 0.3571\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size7 <- sqrt(plant_yield2_lmsum$adj.r.squared)\n\npwr.f2.test(u=3, f2=eff_size7, sig.level=0.05, power=0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 13.69382\n             f2 = 0.8225024\n      sig.level = 0.05\n          power = 0.8\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# N\nceiling(13.69382) + 4\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18\n```\n:::\n:::\n\n\n### Ex 2 (No Prior)\n\nYou are interested in determining if the size of a city (in square miles), number of houses, number of apartments, and number of jobs can predict the population of the city (in # of individuals)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohen.ES(test = \"f2\", size = \"large\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Conventional effect size from Cohen (1982) \n\n           test = f2\n           size = large\n    effect.size = 0.35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.f2.test(u = 3, # 4 Variables\n            f2 = 0.35,  \n            sig.level=0.05, power=0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 31.3129\n             f2 = 0.35\n      sig.level = 0.05\n          power = 0.8\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# N\nceiling(31.3129) + 4\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 36\n```\n:::\n:::\n\n\n## Logistic Reg\n\n- `p0` = $Prob(Y=1|X=0)$: the probability of observing 1 for the outcome\nvariable Y when the predictor X equals 0\n\n- `p1` = $Prob(Y=1|X=1)$: the probability of observing 1 for the outcome\nvariable Y when the predictor X equals 1\n\n\nIn the context of using the `wp.logistic()` function from the \"WebPower\" package in R to calculate the sample size for a logistic regression, the arguments `p0` and `p1` are crucial. They represent the probabilities of the outcome occurring in the two groups you are comparing. Here's how to determine these values:\n\n1. **Understanding `p0` and `p1`**:\n   - `p0`: This is the probability of the event (or the success probability) in the control group or the group without the intervention/exposure.\n   - `p1`: This is the probability of the event in the experimental group or the group with the intervention/exposure.\n\n2. **Obtaining `p0` and `p1`**:\n   - These probabilities are usually obtained from prior research, pilot studies, or literature reviews. You need an estimate of how likely the event is in both the control and experimental groups.\n   - If you're testing a new treatment or intervention, `p1` would be your expected success rate with the treatment, and `p0` would be the success rate observed in the control group or with the standard treatment.\n   - In the absence of prior data, expert opinion or theoretical assumptions might be used to estimate these probabilities.\n\n3. **Example**:\n   - Suppose you are studying a new medication's effect on reducing the incidence of a disease. From previous studies, you know that 20% of patients (0.20 probability) typically show improvement with the current standard medication (`p0`). You expect that 35% of patients (0.35 probability) will show improvement with the new medication (`p1`).\n\n\n\n### Ex 1\n\nYou are interested in determining if body temperature influences sleep disorder prevalence (yes 1, no 0). You collect the following trial data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep_temp <- data.frame(\n  temp = c(98.6, 98.5, 99, 97.5, 98.8, 98.2, 98.5, 98.4, 98.1), \n  sleep_disorder = c(\"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(sleep_temp$temp) # Normal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  sleep_temp$temp\nW = 0.94543, p-value = 0.6401\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep_temp |> \n  ggplot(aes(sleep_disorder, temp, color = sleep_disorder)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](sam-size_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ngeom_point: na.rm = FALSE\nstat_identity: na.rm = FALSE\nposition_identity \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwp.logistic(p0=0.33, p1=0.67, # Why ????\n            alpha=0.05, power=0.80, \n            alternative=\"two.sided\", family=\"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPower for logistic regression\n\n      p0   p1      beta0   beta1        n alpha power\n    0.33 0.67 -0.7081851 1.41637 40.79646  0.05   0.8\n\nURL: http://psychstat.org/logistic\n```\n:::\n:::\n",
    "supporting": [
      "sam-size_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
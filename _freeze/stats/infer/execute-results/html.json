{
  "hash": "f53547c9a12ce7177946483e8504ad49",
  "result": {
    "markdown": "# Infer Package Intro\n\n\n\n\n\n\n\nI will explore [`{infer}`](https://infer.tidymodels.org/index.html) Package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(infer)\nlibrary(dplyr)\n```\n:::\n\n\n## Explore Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(gss)\n#> Rows: 500\n#> Columns: 11\n#> $ year    <dbl> 2014, 1994, 1998, 1996, 1994, 1996, 1990, 2016, 2000, 1998, 20…\n#> $ age     <dbl> 36, 34, 24, 42, 31, 32, 48, 36, 30, 33, 21, 30, 38, 49, 25, 56…\n#> $ sex     <fct> male, female, male, male, male, female, female, female, female…\n#> $ college <fct> degree, no degree, degree, no degree, degree, no degree, no de…\n#> $ partyid <fct> ind, rep, ind, ind, rep, rep, dem, ind, rep, dem, dem, ind, de…\n#> $ hompop  <dbl> 3, 4, 1, 4, 2, 4, 2, 1, 5, 2, 4, 3, 4, 4, 2, 2, 3, 2, 1, 2, 5,…\n#> $ hours   <dbl> 50, 31, 40, 40, 40, 53, 32, 20, 40, 40, 23, 52, 38, 72, 48, 40…\n#> $ income  <ord> $25000 or more, $20000 - 24999, $25000 or more, $25000 or more…\n#> $ class   <fct> middle class, working class, working class, working class, mid…\n#> $ finrela <fct> below average, below average, below average, above average, ab…\n#> $ weight  <dbl> 0.8960034, 1.0825000, 0.5501000, 1.0864000, 1.0825000, 1.08640…\n```\n:::\n\n\n## Specifying Response `specify()`\n\nSpecify response and explanatory variable as formula or arguments.\n\n### Continuous Response\n\n`age` (num) ~ `partyid` (fct)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_spec_age_partyid <- gss %>% \n  specify(age ~ partyid)\n#> Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n\n# Object Type\nsloop::otype(gss_spec_age_partyid)\n#> [1] \"S3\"\n# Class\nclass(gss_spec_age_partyid)\n#> [1] \"infer\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n# Print\ngss_spec_age_partyid\n#> Response: age (numeric)\n#> Explanatory: partyid (factor)\n#> # A tibble: 500 × 2\n#>      age partyid\n#>    <dbl> <fct>  \n#>  1    36 ind    \n#>  2    34 rep    \n#>  3    24 ind    \n#>  4    42 ind    \n#>  5    31 rep    \n#>  6    32 rep    \n#>  7    48 dem    \n#>  8    36 ind    \n#>  9    30 rep    \n#> 10    33 dem    \n#> # … with 490 more rows\n```\n:::\n\n\n\n### Categorical Response\n\nspecifying for inference on proportions\n\nyou will need to use the `success` argument to specify which level of your response variable is a success.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss %>%\n  specify(response = college, success = \"degree\")\n#> Response: college (factor)\n#> # A tibble: 500 × 1\n#>    college  \n#>    <fct>    \n#>  1 degree   \n#>  2 no degree\n#>  3 degree   \n#>  4 no degree\n#>  5 degree   \n#>  6 no degree\n#>  7 no degree\n#>  8 degree   \n#>  9 degree   \n#> 10 no degree\n#> # … with 490 more rows\n```\n:::\n\n\n\n## Declare the NULL Hypothesis\n\ndeclare a null hypothesis using `hypothesize()`.\n\n`null`: \"independence\" or \"point\".\n\n### Test Independence\n\nIf the null hypothesis is that the mean number of hours worked per week in our population is 40, we would write:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss %>%\n  specify(college ~ partyid, success = \"degree\") %>%\n  hypothesize(null = \"independence\")\n#> Dropping unused factor levels DK from the supplied explanatory variable 'partyid'.\n#> Response: college (factor)\n#> Explanatory: partyid (factor)\n#> Null Hypothesis: independence\n#> # A tibble: 500 × 2\n#>    college   partyid\n#>    <fct>     <fct>  \n#>  1 degree    ind    \n#>  2 no degree rep    \n#>  3 degree    ind    \n#>  4 no degree ind    \n#>  5 degree    rep    \n#>  6 no degree rep    \n#>  7 no degree dem    \n#>  8 degree    ind    \n#>  9 degree    rep    \n#> 10 no degree dem    \n#> # … with 490 more rows\n```\n:::\n\n### Test Point Estimate\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40)\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 500 × 1\n#>    hours\n#>    <dbl>\n#>  1    50\n#>  2    31\n#>  3    40\n#>  4    40\n#>  5    40\n#>  6    53\n#>  7    32\n#>  8    20\n#>  9    40\n#> 10    40\n#> # … with 490 more rows\n```\n:::\n\n\n## `generate()` NULL distribution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\n\ngss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40) %>%\n  generate(reps = 1000, type = \"bootstrap\")\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 500,000 × 2\n#> # Groups:   replicate [1,000]\n#>    replicate hours\n#>        <int> <dbl>\n#>  1         1 46.6 \n#>  2         1 43.6 \n#>  3         1 38.6 \n#>  4         1 28.6 \n#>  5         1 38.6 \n#>  6         1 38.6 \n#>  7         1  6.62\n#>  8         1 78.6 \n#>  9         1 38.6 \n#> 10         1 38.6 \n#> # … with 499,990 more rows\n```\n:::\n\n\n\n## Calculate Summary Stats\n\nfind the point estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_mean <- gss %>%\n  specify(response = hours) %>%\n  calculate(stat = \"mean\")\n\nobs_mean\n#> Response: hours (numeric)\n#> # A tibble: 1 × 1\n#>    stat\n#>   <dbl>\n#> 1  41.4\n```\n:::\n\n\ngenerate a null distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist <- gss %>%\n  specify(response = hours) %>%\n  hypothesize(null = \"point\", mu = 40) %>%\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\n\nnull_dist\n#> Response: hours (numeric)\n#> Null Hypothesis: point\n#> # A tibble: 1,000 × 2\n#>    replicate  stat\n#>        <int> <dbl>\n#>  1         1  40.5\n#>  2         2  40.1\n#>  3         3  39.1\n#>  4         4  40.3\n#>  5         5  38.8\n#>  6         6  39.6\n#>  7         7  40.2\n#>  8         8  40.4\n#>  9         9  40.1\n#> 10        10  40.6\n#> # … with 990 more rows\n```\n:::\n\n\n## Visualize Null Dist\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist %>%\n  visualize()\n```\n\n::: {.cell-output-display}\n![](infer_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWhere does our sample’s observed statistic lie on this distribution? We can use the `obs_stat` argument to specify this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist %>%\n  visualize() +\n  shade_p_value(obs_stat = obs_mean, direction = \"two-sided\")\n```\n\n::: {.cell-output-display}\n![](infer_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## P-value\n\nget a two-tailed p-value\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_value <- null_dist %>%\n  get_p_value(obs_stat = obs_mean, direction = \"two-sided\")\n\np_value\n#> # A tibble: 1 × 1\n#>   p_value\n#>     <dbl>\n#> 1   0.038\n```\n:::\n\n\n## Confidence Interval\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate a distribution like the null distribution, \n# though exclude the null hypothesis from the pipeline\nboot_dist <- gss %>%\n  specify(response = hours) %>%\n  generate(reps = 1000, type = \"bootstrap\") %>%\n  calculate(stat = \"mean\")\n\n# start with the bootstrap distribution\nci <- boot_dist %>%\n  # calculate the confidence interval around the point estimate\n  get_confidence_interval(point_estimate = obs_mean,\n                          # at the 95% confidence level\n                          level = .95,\n                          # using the standard error\n                          type = \"se\")\n\nci\n#> # A tibble: 1 × 2\n#>   lower_ci upper_ci\n#>      <dbl>    <dbl>\n#> 1     40.1     42.7\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist %>%\n  visualize() +\n  shade_confidence_interval(endpoints = ci)\n```\n\n::: {.cell-output-display}\n![](infer_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "infer_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}